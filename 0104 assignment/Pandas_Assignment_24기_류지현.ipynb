{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beADODeGPe7H"
      },
      "source": [
        "## Pandas 과제\n",
        "\n",
        "Tabular data의 경우 모델을 돌리기에 앞서서 pandas를 통한 전처리가 많이 필요합니다.\n",
        "\n",
        "다음 과제에서는 판다스에서 가장 자주 쓰이는 함수들을 다룹니다.\n",
        "\n",
        "구글에 올라와 있는 판다스 연습문제 200제 중 중복되는 것, 불필요하다고 생각되는 것을 제외하여 과제를 만들게 되었습니다.\n",
        "\n",
        "넘파이 관련 문제들도 있었지만 판다스로만 과제를 구성하게 되었고, 그것들도 풀어보고 싶은 분들은 아래 출처를 남겨 놓았으니 참고하세요.\n",
        "\n",
        "약 150개 정도로 문제 수가 많지만 기초적인 문제들이 많기 때문에 시간이 좀 걸릴 뿐 큰 어려움은 없을 거라 생각합니다.\n",
        "\n",
        "문제를 풀다보면 부자연스러운 문제도 많이 있지만 그냥 연습 삼아 풀어보시기 바랍니다.\n",
        "\n",
        "관련 csv파일들은 별도의 파일에 담아놓았습니다.\n",
        "\n",
        "\n",
        " 발제자: DA 23기 양진성\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDnagT4ZPe7J"
      },
      "source": [
        "### 출처\n",
        "\n",
        "Author: Avi Chawla\n",
        "\n",
        "LinkedIn: https://www.linkedin.com/in/avi-chawla/\n",
        "\n",
        "Read my blogs here: https://medium.com/@avi_chawla"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ80fJBVPe7K"
      },
      "source": [
        "- **Pandas**\n",
        "\n",
        "1. Pandas Notebook 1: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/Pandas-Notebook-1-d693ac55-6455-40cf-ae34-867c6a02014e/%2Fnotebook.ipynb)\n",
        "2. Pandas Notebook 2: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/Pandas-Notebook-employee-dataset-7e3b6755-5d4b-464b-9b75-9c84667ae3bd/%2Fnotebook.ipynb)\n",
        "\n",
        "3. Pandas Notebook 3: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/Pandas-Notebook-employee-part-2-adc5a3ee-5f61-4725-8e46-ccb07899acfc/%2Fnotebook.ipynb)\n",
        "\n",
        "4. Pandas Notebook 4: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/Pandas-after-employee-f84e02a1-fb6a-428e-af90-8dd99855749a/%2Fnotebook.ipynb) **(This Notebook)**\n",
        "\n",
        "- **NumPy**\n",
        "\n",
        "1. NumPy Notebook 1: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/Numpy-part-1-9b9979f2-b708-4292-b466-3d0157564c91/%2Fnotebook.ipynb)\n",
        "\n",
        "2. NumPy Notebook 2: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/NumPy-Notebook-2-4456411e-2ddd-426d-8027-4881080027db/%2Fnotebook.ipynb)\n",
        "\n",
        "3. NumPy Notebook 3: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/NumPy-Notebook-3-e6587114-b580-4249-b599-540de859e603/%2Fnotebook.ipynb)\n",
        "\n",
        "- **SQL**\n",
        "\n",
        "1. SQL Notebook 1: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/SQL-Notebook-1-eac9d782-a9b1-4e84-a1f9-af14080a6121/%2Fnotebook.ipynb)\n",
        "\n",
        "2. SQL Notebook 2: [Link](https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/SQL-Notebook-2-1914b214-be03-44a1-be63-ad99e98be639/%2Fnotebook.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bac3049910b240b998ba02c52dd9a7cf",
        "deepnote_cell_type": "text-cell-h1",
        "formattedRanges": [],
        "id": "KykzE1swPe7L",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "# Pandas Notebook 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "allow_embed": "code",
        "cell_id": "1247c98b228f4e26a7e645554d1444a0",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 2,
        "execution_start": 1659984470280,
        "id": "rTuCOmrsPe7L",
        "source_hash": "c76c7c51",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "6aaba47726e04be19708d622e44b4594",
        "deepnote_cell_type": "text-cell-h2",
        "formattedRanges": [],
        "id": "wkXGQ6jrPe7M",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "## Create a Pandas DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5134b361d40a48629147a7607e50e333",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "O1s0ril2Pe7N",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 1. Create a DataFrame from a list of lists. Name the columns \"col1\", \"col2\" and \"col3\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cell_id": "e4de38de7b714b368a3ad2cea933f99f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "deepnote_cell_height": 115,
        "deepnote_cell_type": "code",
        "id": "H8SnBl84Pe7O",
        "outputId": "b5dd2265-a4cc-4e05-9c01-9b27723806cb",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   0  1  2\n",
            "0  1  2  3\n",
            "1  4  5  6\n"
          ]
        }
      ],
      "source": [
        "data_list = [[1,2,3], [4,5,6]]\n",
        "df = pd.DataFrame(data_list)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f24b2e095a234294b4782e696a6e5d5a",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "E4pMxJivPe7P",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 2. Create a DataFrame from a list of lists. Name the columns \"col1\", \"col2\" and \"col3\". Change the data type of all columns to \"int8\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "97d8b0c0c0f744fdb856d6fa4acf3ba8",
        "deepnote_cell_height": 133,
        "deepnote_cell_type": "code",
        "id": "GtR-rEdSPe7P",
        "outputId": "c33181de-ba87-422c-f335-2790489e5f9e",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col1  col2  col3\n",
            "0     1     2     3\n",
            "1     4     5     6\n",
            "col1    int8\n",
            "col2    int8\n",
            "col3    int8\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "data_list = [[1,2,3], [4,5,6]]\n",
        "\n",
        "df = pd.DataFrame(data_list, columns=['col1', 'col2', 'col3'])\n",
        "print(df)\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "67608c871eff4c13b387c01d90efb01b",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "Du_NbLAlPe7Q",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 3. Create a DataFrame from a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col1  col2\n",
            "0     1     3\n",
            "1     2     4\n"
          ]
        }
      ],
      "source": [
        "data_dict = {'col1': [1, 2], 'col2': [3, 4]}\n",
        "\n",
        "df = pd.DataFrame(data_dict)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "10a39af80da44666b7cd6b7c76598868",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "wlJa7ZlfPe7Q",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 4. Create a DataFrame from a dictionary. Change the data type to \"int8\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "7db3f0b16fa046df8b556fab1f924448",
        "deepnote_cell_height": 133,
        "deepnote_cell_type": "code",
        "id": "I7QqJqrBPe7R",
        "outputId": "b0f13ebb-ff65-4f71-9ea2-3f5b6c777a12",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col1  col2\n",
            "0     1     3\n",
            "1     2     4\n",
            "col1    int8\n",
            "col2    int8\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "data_dict = {'col1': [1, 2], 'col2': [3, 4]}\n",
        "\n",
        "df = pd.DataFrame(data_dict)\n",
        "print(df)\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c4f04239427b4dfeb371b7f85167aa59",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "jcc02BedPe7R",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 5. Create a DataFrame from a numpy array. Name the columns \"col1\", \"col2\" and \"col3\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "6db2cc59b35d44308ee927877e504b67",
        "deepnote_cell_height": 115,
        "deepnote_cell_type": "code",
        "id": "6LtDEnvXPe7R",
        "outputId": "190fffe3-3ec8-4c74-8fb2-3670f9da0163",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col1  col2  col3\n",
            "0     1     2     3\n",
            "1     4     5     6\n"
          ]
        }
      ],
      "source": [
        "data_nparray = np.array([[1,2,3], [4,5,6]])\n",
        "\n",
        "df =  pd.DataFrame(data_nparray)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "de1e8331c49f4f5c93f0c72c4b7ba203",
        "deepnote_cell_type": "text-cell-h2",
        "formattedRanges": [],
        "id": "3N9Xe_ZiPe7S",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "## Input Operations from CSV in Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "141fc7656f334da2bbb5d43f40bec4c2",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "YKakQqVvPe7S",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 6. Read a CSV File."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cell_id": "7d5f6e2c60c741ab9f5fae8b7bf5feb0",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 1,
        "execution_start": 1659896158632,
        "id": "u_F5HmvgPe7T",
        "outputId": "4fbd1e3a-6e2f-499e-d6f9-2c442234ea0e",
        "source_hash": "b623e53d",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col1  col2  col3\n",
            "0     1     2     3\n",
            "1     4     5     6\n",
            "2     7     8     9\n"
          ]
        }
      ],
      "source": [
        "csv_file = 'input_data/file1.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "8f9a70588d944fd78abeea0971687a56",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "g90sJh5kPe7T",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 7. Read a CSV file with delimiter \"|\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "cell_id": "0f8de42d5a9b4909b6c21941137d5b04",
        "deepnote_cell_height": 115,
        "deepnote_cell_type": "code",
        "id": "BeKTQdcmPe7T",
        "outputId": "7e47983f-e22f-4216-c014-30e2cfb20073",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col1  col2  col3\n",
            "0     1     2     3\n",
            "1     4     5     6\n",
            "2     7     8     9\n"
          ]
        }
      ],
      "source": [
        "csv_file = \"input_data/file2.csv\"\n",
        "\n",
        "df = pd.read_csv(csv_file, delimiter='|')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "2c4f52473db24da6baa0a5129e176a59",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "kQCSSLicPe7U",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 8. Read a CSV file with no header column and use \"col1\", \"col2\" and \"col3\" as column names. The delimiter is \",\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "cell_id": "e84bf940f16945cd9d91441af3658be3",
        "deepnote_cell_height": 115,
        "deepnote_cell_type": "code",
        "id": "P-EtPMFOPe7U",
        "outputId": "9def46b4-59d5-4c7d-c010-66dff3419aee",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col1  col2  col3\n",
            "0     1     2     3\n",
            "1     4     5     6\n",
            "2     7     8     9\n"
          ]
        }
      ],
      "source": [
        "csv_file = \"input_data/file3.csv\"\n",
        "\n",
        "df = pd.read_csv(csv_file, header=None, names=['col1', 'col2', 'col3'])\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "4842addbe893458f80df0837f055a5fa",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "BrFL-jkpPe7U",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 9. There are 3 columns in the file, namely \"col1\", \"col2\", and \"col3\". You have to read only \"col1\" and \"col3\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "cell_id": "602030d5cc4047efba6be2bb7084e468",
        "deepnote_cell_height": 115,
        "deepnote_cell_type": "code",
        "id": "g6-gASVZPe7V",
        "outputId": "f26ae8da-778e-4ad4-b825-6adb4d23be24",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col1  col3\n",
            "0     1     3\n",
            "1     4     6\n",
            "2     7     9\n"
          ]
        }
      ],
      "source": [
        "csv_file = \"input_data/file1.csv\"\n",
        "\n",
        "df = pd.read_csv(csv_file, usecols=['col1', 'col3']) \n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7810864401e849a2984e5287d89be7bc",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "940C9oE1Pe7V",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 10. There are 3 columns in the file, namely \"col1\", \"col2\", and \"col3\". You have to read only \"col1\" and \"col3\". Moreover, the delimiter is \"|\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "cell_id": "212e480c629b4a0e8949dc763a78b44b",
        "deepnote_cell_height": 115,
        "deepnote_cell_type": "code",
        "id": "sRHk1bqbPe7V",
        "outputId": "7783c150-3f21-4f4b-b912-91e36e402e8d",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col1  col3\n",
            "0     1     3\n",
            "1     4     6\n",
            "2     7     9\n"
          ]
        }
      ],
      "source": [
        "csv_file = \"input_data/file2.csv\"\n",
        "df =  pd.read_csv(csv_file,usecols=['col1', 'col3'], delimiter='|')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "1311297a04c94a60b908f99e5f355fa4",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "QEYVqQlvPe7V",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 11. The file \"file4.csv\" has junk characters in the first two lines. You have to read the CSV file from the 3rd line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "cell_id": "99001d5c13b944c0a9c833b621cd995c",
        "deepnote_cell_height": 115,
        "deepnote_cell_type": "code",
        "id": "_rMsJnt_Pe7W",
        "outputId": "ceea9481-e231-4e5a-896b-8b95825b2648",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col1  col2  col3\n",
            "0     1     2     3\n",
            "1     4     5     6\n",
            "2     7     8     9\n"
          ]
        }
      ],
      "source": [
        "csv_file = \"input_data/file4.csv\"\n",
        "df = pd.read_csv(csv_file, skiprows=2)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e1b751a1ad2c4a08b4434020f09a6dc9",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "l1gAeKEWPe7W",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 12. There are 3 columns in the file, namely \"col1\", \"col2\", and \"col3\". While reading the CSV file, specify the data type of \"col1\" as 'int32'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "cell_id": "3193f911f1194a71a3de98cdbcf1fe8b",
        "deepnote_cell_height": 115,
        "deepnote_cell_type": "code",
        "id": "8TO1Mc9IPe7W",
        "outputId": "e718622c-e16e-4a3b-b0ae-adbf2042306c",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col1  col2  col3\n",
            "0     1     2     3\n",
            "1     4     5     6\n",
            "2     7     8     9\n"
          ]
        }
      ],
      "source": [
        "csv_file = \"input_data/file1.csv\"\n",
        "df =  pd.read_csv(csv_file, dtype={'col1': np.int32})\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "1056a6c67708428cac87081b592c3acf",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "z3ENfAv8Pe7W",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 13. The first column in the CSV file holds index values of the dataframe. Read it so that the first column goes as the index column of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "cell_id": "6b910dc50ef14e558183ece164dd34e7",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 14,
        "execution_start": 1659897460042,
        "id": "CY2m5g6gPe7X",
        "outputId": "4096a6c2-940d-4cce-f17e-0730e77daead",
        "source_hash": "6f4f6738",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col1  col2  col3\n",
            "0     1     2     3\n",
            "1     4     5     6\n",
            "2     7     8     9\n"
          ]
        }
      ],
      "source": [
        "csv_file = \"input_data/file5.csv\"\n",
        "df =  pd.read_csv(csv_file, index_col=0 )\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "749a612e37d5450fa50cbbb1069605fa",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "P6NA0Iu9Pe7X",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 14. There are 9 data rows in the CSV file. Read only the first 4 of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ed48b92ae82e461190405bad227fd38e",
        "deepnote_cell_type": "text-cell-p",
        "formattedRanges": [
          {
            "fromCodePoint": 0,
            "marks": {
              "bold": true
            },
            "toCodePoint": 100
          }
        ],
        "id": "JJ0Oo_KuPe7X",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "Note: You should NOT read the whole CSV file and use the head() method to select the first 4 rows. 🚫"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "cell_id": "31944423ea9f473eb632efa25beb1e3a",
        "deepnote_cell_height": 115,
        "deepnote_cell_type": "code",
        "id": "xj8-6FE-Pe7Y",
        "outputId": "935720a5-803b-497c-8a9e-72cdc3e6a28c",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col1  col2  col3\n",
            "0     1     2     3\n",
            "1     4     5     6\n",
            "2     7     8     9\n",
            "3     1     2     3\n"
          ]
        }
      ],
      "source": [
        "csv_file = \"input_data/file6.csv\"\n",
        "df = df.head(4)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b868eef4ed9745ddb43d318872c2b544",
        "deepnote_cell_type": "text-cell-h2",
        "formattedRanges": [],
        "id": "Ia9jtNaIPe7Y",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "## Output Operations to CSV in Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "4b17329401414c36856ca40b2b8dcbdc",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "UXuPWB7RPe7Y",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 16. Given the dataframe \"df\", store it to a CSV File (with the index values)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "cell_id": "b20aa89229a7415faacffa8aa7005698",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 1,
        "execution_start": 1659898703469,
        "id": "7w7NW4jwPe7Y",
        "source_hash": "a0acabfa",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame([[1,2,3], [4,5,6]],\n",
        "                  columns = [\"col1\", \"col2\", \"col3\"])\n",
        "\n",
        "csv_file = \"output_data/file1.csv\"\n",
        "\n",
        "df.to_csv(csv_file, index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "87c763b753ee4fbfa191b663c4830fc8",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "-yyF5XxzPe7Z",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 17. Given the dataframe \"df\", store it to a CSV File without the index column this time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "cell_id": "55d0e76c18d4462aa24a9f76a4560f48",
        "deepnote_cell_height": 241,
        "deepnote_cell_type": "code",
        "id": "qx2FkS6XPe7Z",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame([[1,2,3], [4,5,6]],\n",
        "                  columns = [\"col1\", \"col2\", \"col3\"])\n",
        "\n",
        "csv_file = \"output_data/file2.csv\"\n",
        "\n",
        "## Start your code here\n",
        "df.to_csv(csv_file, index=False) # index column없으려면 False\n",
        "## End your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "6b27e6de89e44613a9a0b497fd8a96a0",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "I1u3GsTGPe7Z",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### 20. Given a dataframe \"df\" with three columns -- \"col1\", \"col2\" and \"col3\". Store the DataFrame to a CSV file without the column row ( and without the index values)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "cell_id": "52df84f7732a4015a50c32a98328d324",
        "deepnote_cell_height": 241,
        "deepnote_cell_type": "code",
        "id": "vqsWycSQPe7a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame([[1,2,3], [4,5,6]],\n",
        "                  columns = [\"col1\", \"col2\", \"col3\"])\n",
        "\n",
        "csv_file = \"output_data/file5.csv\"\n",
        "\n",
        "\n",
        "## Start your code here\n",
        "df.to_csv(csv_file, index=False, header=False)\n",
        "## End your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8MPhhTyPe7a"
      },
      "source": [
        "# Pandas Notebook 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRFI2tUFPe7a"
      },
      "source": [
        "### 31. Read the CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PJY-gpfTPe7a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "RuZ1cwTZPe7b",
        "outputId": "a7f06ea8-a171-4677-c670-95acce9dfe6e"
      },
      "outputs": [],
      "source": [
        "file_name = \"employee_dataset.csv\"\n",
        "\n",
        "df = pd.read_csv('input_data/' + file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M98JN2YiPe7b"
      },
      "source": [
        "### 32. Print the first 5 rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "O2PCwb1uPe7b",
        "outputId": "e2f8be26-1603-4c69-95cb-a44a5f7bbaa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             Name                  Company_Name  \\\n",
            "0  Spencer Adkins                James and Sons   \n",
            "1    Julie Morton                 Nichols-James   \n",
            "2    Matthew Hall                     Scott Inc   \n",
            "3      Brad Scott  Johnston, Fleming and Tanner   \n",
            "4   Theresa Owens      Baker, Allen and Edwards   \n",
            "\n",
            "                        Employee_Job_Title      Employee_City  \\\n",
            "0                          Equities trader     New Russellton   \n",
            "1  Diplomatic Services operational officer  North Melissafurt   \n",
            "2               Regulatory affairs officer           Wardfort   \n",
            "3                      Production engineer     West Jamesview   \n",
            "4                      Production engineer          Whiteside   \n",
            "\n",
            "        Employee_Country  Employee_Salary Employment_Status  Employee_Rating  \n",
            "0  Palestinian Territory           321520         Full Time              3.9  \n",
            "1       Marshall Islands           589090         Full Time              4.3  \n",
            "2               Anguilla           630890         Full Time              3.1  \n",
            "3   Syrian Arab Republic           116400         Full Time              3.1  \n",
            "4               Dominica           523499         Full Time              4.8  \n"
          ]
        }
      ],
      "source": [
        "print(df.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQcqyqLJPe7c"
      },
      "source": [
        "### 33. Print the last 10 rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "GKJy1iypPe7c",
        "outputId": "c83118ac-5da3-40e6-a298-b22c89341ff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                     Name                  Company_Name  \\\n",
            "299990      Monica Bender    Wallace, Smith and Shepard   \n",
            "299991  William Rodriguez                     Scott Inc   \n",
            "299992    Steven Thornton      Baker, Allen and Edwards   \n",
            "299993         Terry Hill       White, Mcclain and Cobb   \n",
            "299994      Kelly Bennett       White, Mcclain and Cobb   \n",
            "299995         Nancy Neal              Bullock-Carrillo   \n",
            "299996     Michele Butler  Johnston, Fleming and Tanner   \n",
            "299997        Lynn Wilson                 Nichols-James   \n",
            "299998      Lindsey Keith                 Nichols-James   \n",
            "299999      Karen Delgado                James and Sons   \n",
            "\n",
            "                  Employee_Job_Title      Employee_City Employee_Country  \\\n",
            "299990           Production engineer   New Cindychester       Bangladesh   \n",
            "299991                    Ergonomist          Whiteside      New Zealand   \n",
            "299992               Patent examiner         Aliciafort            Benin   \n",
            "299993  Investment banker, corporate   New Cindychester           Sweden   \n",
            "299994     Radiographer, therapeutic           Wardfort             Fiji   \n",
            "299995                   Optometrist  North Melissafurt            Samoa   \n",
            "299996                 Administrator         Aliciafort             Cuba   \n",
            "299997                 Administrator   New Cindychester          Bolivia   \n",
            "299998                          Make       Whitakerbury   Western Sahara   \n",
            "299999                       Actuary     New Russellton   United Kingdom   \n",
            "\n",
            "        Employee_Salary Employment_Status  Employee_Rating  \n",
            "299990           852660         Full Time              3.0  \n",
            "299991           214400         Full Time              1.5  \n",
            "299992            60240         Full Time              4.3  \n",
            "299993           414720            Intern              2.3  \n",
            "299994           182270         Full Time              3.6  \n",
            "299995            99670            Intern              3.3  \n",
            "299996           949580            Intern              2.6  \n",
            "299997           802830         Full Time              0.6  \n",
            "299998           257240         Full Time              2.4  \n",
            "299999           575770            Intern              3.3  \n"
          ]
        }
      ],
      "source": [
        "### 33. Print the last 10 rows.\n",
        "print(df.tail(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ09-bBsPe7c"
      },
      "source": [
        "### 34. Print the number of rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "KuObAWtcPe7c",
        "outputId": "20954792-2c87-4e25-ec9e-917b25da20fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "300000\n"
          ]
        }
      ],
      "source": [
        "rows= len(df.index)\n",
        "\n",
        "print(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36z79pvEPe7d"
      },
      "source": [
        "### 35. Print the number of columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "gNnJ2DVPPe7d",
        "outputId": "d5eaba2c-3f0b-4d04-dea8-e8cc708cbbff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "columns = len(df.columns)\n",
        "\n",
        "print(columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZaHhchmPe7d"
      },
      "source": [
        "### 36. Print all column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "znaznLAQPe7e",
        "outputId": "e63403b2-a517-46cc-ca56-f3c8b5fe3576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Name', 'Company_Name', 'Employee_Job_Title', 'Employee_City',\n",
            "       'Employee_Country', 'Employee_Salary', 'Employment_Status',\n",
            "       'Employee_Rating'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "column_names = df.columns\n",
        "\n",
        "print(column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eZLfNvJPe7e"
      },
      "source": [
        "### 37. Print the mean of Employee_Salary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "c-eQJUmhPe7e",
        "outputId": "1ff5c6e6-2080-4451-8912-ba4f63548147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500224.20772666665\n"
          ]
        }
      ],
      "source": [
        "print(df['Employee_Salary'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO3LQ_f-Pe7f"
      },
      "source": [
        "### 38. Print the mean of Employee_Rating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "2s3dR7QIPe7f",
        "outputId": "67038b7f-3dd2-4801-d70f-5fe067346592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5059550000000006\n"
          ]
        }
      ],
      "source": [
        "print(df['Employee_Rating'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtFXGUC-Pe7f"
      },
      "source": [
        "### 39. Print the number of distinct Company_Name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "sPow8DB7Pe7f",
        "outputId": "c9498c07-4e00-45ee-a873-4e846b4f03d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n"
          ]
        }
      ],
      "source": [
        "print(len(df['Company_Name'].unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF38vWT_Pe7g"
      },
      "source": [
        "### 41. Print the number of employees working in the company \"Nichols-James\".  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "pfd8wPtvPe7g",
        "outputId": "f1280e9f-e1d3-4a1e-843f-7aff579ca8cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19911\n"
          ]
        }
      ],
      "source": [
        "### 41. Print the number of employees working in the company \"Nichols-James\".  \n",
        "print(len(df[df['Company_Name'] == 'Nichols-James']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKzNLeK-Pe7g"
      },
      "source": [
        "### 42-44. Print the maximum, minimum and median Employee_Salary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "a7lZQiOfPe7h",
        "outputId": "2ae39ddb-70f2-4a76-eba8-bf9b86f56cfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "999990\n",
            "0\n",
            "500780.0\n"
          ]
        }
      ],
      "source": [
        "print(df['Employee_Salary'].max())\n",
        "print(df['Employee_Salary'].min())\n",
        "print(df['Employee_Salary'].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhA9d_HBPe7h"
      },
      "source": [
        "### 45-49. Print the distribution of the following columns: (the frequency of individual entries)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmkYNF-qPe7h"
      },
      "source": [
        "1. Company_Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "StXexFd3Pe7i",
        "outputId": "cba5807a-7e98-49b1-9497-68498da8d33b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Company_Name\n",
            "Scott Inc                         20390\n",
            "White, Mcclain and Cobb           20261\n",
            "Thomas-Spencer                    20142\n",
            "Nelson-Li                         20132\n",
            "Taylor-Ramos                      20122\n",
            "Baker, Allen and Edwards          20084\n",
            "Matthews Inc                      20083\n",
            "Bullock-Carrillo                  20063\n",
            "Andrade LLC                       19983\n",
            "Campos, Reynolds and Mccormick    19927\n",
            "Nichols-James                     19911\n",
            "James and Sons                    19868\n",
            "Marshall-Holloway                 19859\n",
            "Johnston, Fleming and Tanner      19811\n",
            "Wallace, Smith and Shepard        19364\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df['Company_Name'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbmPWWYdPe7i"
      },
      "source": [
        "2. Employee_Job_Title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "mUZmERtrPe7i",
        "outputId": "d13e9293-b63a-48e0-8ab8-b50a89cab31e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Employee_Job_Title\n",
            "Diplomatic Services operational officer                  30137\n",
            "Administrator                                            15222\n",
            "Garment/textile technologist                             15183\n",
            "Trading standards officer                                15155\n",
            "Patent examiner                                          15085\n",
            "Armed forces logistics/support/administrative officer    15050\n",
            "Retail merchandiser                                      15033\n",
            "Energy manager                                           15033\n",
            "Actuary                                                  15030\n",
            "Investment banker, corporate                             15008\n",
            "Ergonomist                                               15006\n",
            "Production engineer                                      15003\n",
            "Equities trader                                          15000\n",
            "Naval architect                                          14905\n",
            "Radiographer, therapeutic                                14882\n",
            "Regulatory affairs officer                               14869\n",
            "Optometrist                                              14838\n",
            "Sales promotion account executive                        14820\n",
            "Make                                                     14741\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df['Employee_Job_Title'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2EiOe2yPe7j"
      },
      "source": [
        "### 50. Print the company with the most number of employees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "o6tZBNTiPe7j",
        "outputId": "4d358203-4047-4e03-809c-41b84441eef6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scott Inc\n"
          ]
        }
      ],
      "source": [
        "print(df['Company_Name'].value_counts().index[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loGRB7JnPe7j"
      },
      "source": [
        "### 51. Print the number of employees in the above company."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "VYcL64IzPe7j",
        "outputId": "855b5144-0e02-491e-fd04-d47146e4a344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20390\n"
          ]
        }
      ],
      "source": [
        "print(df['Company_Name'].value_counts().values[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XKdd2P1Pe7k"
      },
      "source": [
        "### 52. Print the company with the least number of employees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "JRHYqgqHPe7k",
        "outputId": "9d2d6862-cb2e-419f-9eab-c2f43a843812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wallace, Smith and Shepard\n"
          ]
        }
      ],
      "source": [
        "print(df['Company_Name'].value_counts().index[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWV2nS53Pe7k"
      },
      "source": [
        "### 53. Print the number of employees in the above company."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "gCgzjRSDPe7l",
        "outputId": "4f1dd362-b0a8-44f5-b941-c3b480f4fe9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19364\n"
          ]
        }
      ],
      "source": [
        "print(df['Company_Name'].value_counts().values[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwt8jEUlPe7l"
      },
      "source": [
        "### 54. Print the employee details with the maximum salary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "E_KOJFbUPe7l",
        "outputId": "f5de4eee-e994-4130-e5ef-e32875f9f3f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              Name  Company_Name   Employee_Job_Title Employee_City  \\\n",
            "70356  Anna Lawson  Taylor-Ramos  Production engineer   Kristaburgh   \n",
            "\n",
            "      Employee_Country  Employee_Salary Employment_Status  Employee_Rating  \n",
            "70356          Lesotho           999990         Full Time              4.0  \n"
          ]
        }
      ],
      "source": [
        "print(df[df['Employee_Salary'] == df['Employee_Salary'].max()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3gwGGlnPe7l"
      },
      "source": [
        "### 55. Print the employee details with the maximum rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "3yPotJ-MPe7m",
        "outputId": "d02434d5-d04e-44fd-cad2-bff930c4b220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                    Name                  Company_Name  \\\n",
            "124       Joshua Huffman                James and Sons   \n",
            "342         Alan Carlson      Baker, Allen and Edwards   \n",
            "391         Lisa Summers  Johnston, Fleming and Tanner   \n",
            "395        Timothy Woods  Johnston, Fleming and Tanner   \n",
            "415      Cameron Hawkins                  Taylor-Ramos   \n",
            "...                  ...                           ...   \n",
            "299689    Michael Jordan  Johnston, Fleming and Tanner   \n",
            "299855  Rebecca Garrison                     Nelson-Li   \n",
            "299900      Daniel Jones                  Taylor-Ramos   \n",
            "299906     Justin Mendez              Bullock-Carrillo   \n",
            "299973      Doris Miller                   Andrade LLC   \n",
            "\n",
            "                                       Employee_Job_Title      Employee_City  \\\n",
            "124                          Garment/textile technologist     New Russellton   \n",
            "342               Diplomatic Services operational officer        Kristaburgh   \n",
            "391                            Regulatory affairs officer  North Melissafurt   \n",
            "395                          Garment/textile technologist          Whiteside   \n",
            "415     Armed forces logistics/support/administrative ...           Wardfort   \n",
            "...                                                   ...                ...   \n",
            "299689                                    Naval architect       Whitakerbury   \n",
            "299855                                Production engineer       Whitakerbury   \n",
            "299900                  Sales promotion account executive        Kristaburgh   \n",
            "299906                         Regulatory affairs officer   New Cindychester   \n",
            "299973  Armed forces logistics/support/administrative ...           Wardfort   \n",
            "\n",
            "                    Employee_Country  Employee_Salary Employment_Status  \\\n",
            "124                     Cook Islands           694760         Full Time   \n",
            "342                         Mongolia           491710            Intern   \n",
            "391                             Togo           933500         Full Time   \n",
            "395     United States Virgin Islands           367630         Full Time   \n",
            "415                         Tanzania            66570            Intern   \n",
            "...                              ...              ...               ...   \n",
            "299689                   Philippines           474540         Full Time   \n",
            "299855                       Ireland           592530         Full Time   \n",
            "299900                  Sierra Leone            32160         Full Time   \n",
            "299906                      Colombia           374540         Full Time   \n",
            "299973                    Kazakhstan           943340            Intern   \n",
            "\n",
            "        Employee_Rating  \n",
            "124                 5.0  \n",
            "342                 5.0  \n",
            "391                 5.0  \n",
            "395                 5.0  \n",
            "415                 5.0  \n",
            "...                 ...  \n",
            "299689              5.0  \n",
            "299855              5.0  \n",
            "299900              5.0  \n",
            "299906              5.0  \n",
            "299973              5.0  \n",
            "\n",
            "[2985 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df[df['Employee_Rating']==df['Employee_Rating'].max()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgz8LldiPe7m"
      },
      "source": [
        "### 56. Print the Company_Name with most number of employees in 'Wardfort' city."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aU9l8U7oPe7m",
        "outputId": "be87ee64-a8f8-4a79-938f-6d87474ed61f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'White, Mcclain and Cobb'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(df[df['Employee_City']=='Wardfort']['Company_Name'].value_counts().index[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_doqegn7Pe7m"
      },
      "source": [
        "### 57. Change the Data type of 'Employee_Salary' column to float."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "lFtrj_JvPe7n",
        "outputId": "9ef53ee2-bfda-484c-8a56-6dfba1dded04"
      },
      "outputs": [],
      "source": [
        "df['Employee_Salary'] = df['Employee_Salary'].astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPsIGcWFPe7n"
      },
      "source": [
        "### 58. Print the Employee_City with the most number of 'Production engineer'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "KPbD3ZwiPe7n",
        "outputId": "d360ae7f-2e41-4b66-e941-ec6e11b8c47b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aliciafort\n"
          ]
        }
      ],
      "source": [
        "print(df[df['Employee_Job_Title']=='Production engineer']['Employee_City'].value_counts().index[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKOu4R3ZPe7o"
      },
      "source": [
        "### 60. Print the Company_Name with the highest average 'Employee_Rating'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "T_DF6WMMPe7o",
        "outputId": "54785322-e4bc-4eb8-cf98-4b5721982ed1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matthews Inc\n"
          ]
        }
      ],
      "source": [
        "print(df.groupby('Company_Name')['Employee_Rating'].mean().sort_values(ascending=False).index[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plWyodOaPe7o"
      },
      "source": [
        "### 61. Print the number of employees working in 'Ricardomouth' and 'Kristaburgh' location combined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "1mvb7kg4Pe7o",
        "outputId": "9a82addf-87c0-451d-f4ea-14d26cae04cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60256\n"
          ]
        }
      ],
      "source": [
        "print(len(df[(df['Employee_City']=='Ricardomouth') | (df['Employee_City']=='Kristaburgh')]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryie2eUbPe7p"
      },
      "source": [
        "### 62. Print the distinct Company_Name corresponding to the 5 highest paid employees in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Ft5TXbjwPe7p",
        "outputId": "257c3b47-c21a-442d-c764-2df103d71e7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Taylor-Ramos' 'Thomas-Spencer' 'White, Mcclain and Cobb'\n",
            " 'Campos, Reynolds and Mccormick' 'James and Sons']\n"
          ]
        }
      ],
      "source": [
        "### 62. Print the distinct Company_Name corresponding to the 5 highest paid employees in the dataset.\n",
        "print(df.sort_values(by='Employee_Salary', ascending=False)['Company_Name'].unique()[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR8doOxpPe7p"
      },
      "source": [
        "### 63. Check if there are any duplicate rows in the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "KppX5uQUPe7p",
        "outputId": "b37b4cac-c376-41c2-d62a-bfe011b85cfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0         False\n",
            "1         False\n",
            "2         False\n",
            "3         False\n",
            "4         False\n",
            "          ...  \n",
            "299995    False\n",
            "299996    False\n",
            "299997    False\n",
            "299998    False\n",
            "299999    False\n",
            "Length: 300000, dtype: bool\n"
          ]
        }
      ],
      "source": [
        "print(df.duplicated())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCNbZCHRPe7q"
      },
      "source": [
        "### 64. Check if any of the columns has NaN values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "4nDFkQI4Pe7q",
        "outputId": "2e8835a7-221e-4c36-adad-dce1c444ee41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name                  False\n",
            "Company_Name          False\n",
            "Employee_Job_Title    False\n",
            "Employee_City         False\n",
            "Employee_Country      False\n",
            "Employee_Salary       False\n",
            "Employment_Status     False\n",
            "Employee_Rating       False\n",
            "dtype: bool\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().any())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG-2nU40Pe7q"
      },
      "source": [
        "### 65. Print the data type of every column in the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "Mjs07JjUPe7q",
        "outputId": "9143da65-8423-43b4-9d33-aa61a442da10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name                   object\n",
            "Company_Name           object\n",
            "Employee_Job_Title     object\n",
            "Employee_City          object\n",
            "Employee_Country       object\n",
            "Employee_Salary       float64\n",
            "Employment_Status      object\n",
            "Employee_Rating       float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UqINySMPe7q"
      },
      "source": [
        "### 66. Print the Company_Name column only as a Series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUzEhpEQPe7r",
        "outputId": "6e891dde-7075-45ea-f224-394674513eb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                       James and Sons\n",
              "1                        Nichols-James\n",
              "2                            Scott Inc\n",
              "3         Johnston, Fleming and Tanner\n",
              "4             Baker, Allen and Edwards\n",
              "                      ...             \n",
              "299995                Bullock-Carrillo\n",
              "299996    Johnston, Fleming and Tanner\n",
              "299997                   Nichols-James\n",
              "299998                   Nichols-James\n",
              "299999                  James and Sons\n",
              "Name: Company_Name, Length: 300000, dtype: object"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(df['Company_Name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SroDaTjqPe7r"
      },
      "source": [
        "### 67. Print the Company_Name column only as a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "bAF-dEwFPe7r",
        "outputId": "173d1877-03ce-4d3d-afcd-0198b32b9e19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Company_Name\n",
            "0                     James and Sons\n",
            "1                      Nichols-James\n",
            "2                          Scott Inc\n",
            "3       Johnston, Fleming and Tanner\n",
            "4           Baker, Allen and Edwards\n",
            "...                              ...\n",
            "299995              Bullock-Carrillo\n",
            "299996  Johnston, Fleming and Tanner\n",
            "299997                 Nichols-James\n",
            "299998                 Nichols-James\n",
            "299999                James and Sons\n",
            "\n",
            "[300000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df[['Company_Name']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r1AUrqpPe7r"
      },
      "source": [
        "### 68. Select the 'Employee_Job_Title' and 'Employee_City' column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "4loNllBJPe7s",
        "outputId": "6fd4ddaa-3fcf-40ef-9383-a99bccab62cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                             Employee_Job_Title      Employee_City\n",
            "0                               Equities trader     New Russellton\n",
            "1       Diplomatic Services operational officer  North Melissafurt\n",
            "2                    Regulatory affairs officer           Wardfort\n",
            "3                           Production engineer     West Jamesview\n",
            "4                           Production engineer          Whiteside\n",
            "...                                         ...                ...\n",
            "299995                              Optometrist  North Melissafurt\n",
            "299996                            Administrator         Aliciafort\n",
            "299997                            Administrator   New Cindychester\n",
            "299998                                     Make       Whitakerbury\n",
            "299999                                  Actuary     New Russellton\n",
            "\n",
            "[300000 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df[['Employee_Job_Title', 'Employee_City']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCpHw5-rPe7s"
      },
      "source": [
        "### 69. Print the number of employees with Employee_Rating greater than the average Employee_Rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "9A_4kpmcPe7s",
        "outputId": "a3630f28-722d-4780-d47d-4e11f13ec579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "147548\n"
          ]
        }
      ],
      "source": [
        "print(len(df[df['Employee_Rating'].mean() < df['Employee_Rating']]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-yMx-0vPe7s"
      },
      "source": [
        "### 74. Print the first 5 rows of the first 5 columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "FfyboFnVPe7t",
        "outputId": "819b7e1f-7722-46aa-a116-424830067bcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             Name                  Company_Name  \\\n",
            "0  Spencer Adkins                James and Sons   \n",
            "1    Julie Morton                 Nichols-James   \n",
            "2    Matthew Hall                     Scott Inc   \n",
            "3      Brad Scott  Johnston, Fleming and Tanner   \n",
            "4   Theresa Owens      Baker, Allen and Edwards   \n",
            "\n",
            "                        Employee_Job_Title      Employee_City  \\\n",
            "0                          Equities trader     New Russellton   \n",
            "1  Diplomatic Services operational officer  North Melissafurt   \n",
            "2               Regulatory affairs officer           Wardfort   \n",
            "3                      Production engineer     West Jamesview   \n",
            "4                      Production engineer          Whiteside   \n",
            "\n",
            "        Employee_Country  \n",
            "0  Palestinian Territory  \n",
            "1       Marshall Islands  \n",
            "2               Anguilla  \n",
            "3   Syrian Arab Republic  \n",
            "4               Dominica  \n"
          ]
        }
      ],
      "source": [
        "# first 5 rows of the first 5 columns\n",
        "print(df.iloc[:5,:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlV2l7QZPe7t"
      },
      "source": [
        "### 76. Print the number of employees whose first name starts with the letter 'V'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "RbiShQ15Pe7t",
        "outputId": "f9d4cd0a-68bf-4cdf-b2fd-a69d179752fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3683\n"
          ]
        }
      ],
      "source": [
        "print(len(df[df['Name'].str.startswith('V')]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5dya3v-Pe7t"
      },
      "source": [
        "### 77. Print the number of employees whose last name starts with the letter 'R'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "_qKIhg0MPe7t",
        "outputId": "ff575a56-3903-4630-adb6-e1b226b26060"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20712\n",
            "                     Name                Company_Name  \\\n",
            "17              Gail Rose              Thomas-Spencer   \n",
            "26        Donna Rodriguez              Thomas-Spencer   \n",
            "28           Kim Reynolds           Marshall-Holloway   \n",
            "39          Jessica Reyes              Thomas-Spencer   \n",
            "55            Amanda Roth                Taylor-Ramos   \n",
            "...                   ...                         ...   \n",
            "299902  Michelle Reynolds           Marshall-Holloway   \n",
            "299905       Sandra Riley  Wallace, Smith and Shepard   \n",
            "299964   Joshua Rodriguez                 Andrade LLC   \n",
            "299967       James Rhodes                Matthews Inc   \n",
            "299991  William Rodriguez                   Scott Inc   \n",
            "\n",
            "                       Employee_Job_Title      Employee_City  \\\n",
            "17                        Patent examiner       Whitakerbury   \n",
            "26      Sales promotion account executive          Whiteside   \n",
            "28                                Actuary     West Jamesview   \n",
            "39           Garment/textile technologist        Kristaburgh   \n",
            "55                          Administrator  North Melissafurt   \n",
            "...                                   ...                ...   \n",
            "299902                               Make           Wardfort   \n",
            "299905                     Energy manager          Whiteside   \n",
            "299964          Trading standards officer   New Cindychester   \n",
            "299967                Production engineer   New Cindychester   \n",
            "299991                         Ergonomist          Whiteside   \n",
            "\n",
            "                Employee_Country  Employee_Salary Employment_Status  \\\n",
            "17                       Finland         178570.0         Full Time   \n",
            "26                          Guam         622920.0         Full Time   \n",
            "28                 Faroe Islands         794450.0         Full Time   \n",
            "39                      Botswana         667490.0         Full Time   \n",
            "55                     Macedonia         437720.0         Full Time   \n",
            "...                          ...              ...               ...   \n",
            "299902               El Salvador         105680.0         Full Time   \n",
            "299905  Northern Mariana Islands          34760.0         Full Time   \n",
            "299964              Sierra Leone         118300.0         Full Time   \n",
            "299967                  Honduras         386610.0         Full Time   \n",
            "299991               New Zealand         214400.0         Full Time   \n",
            "\n",
            "        Employee_Rating  \n",
            "17                  1.9  \n",
            "26                  2.8  \n",
            "28                  1.4  \n",
            "39                  0.7  \n",
            "55                  0.7  \n",
            "...                 ...  \n",
            "299902              4.8  \n",
            "299905              2.0  \n",
            "299964              1.1  \n",
            "299967              1.4  \n",
            "299991              1.5  \n",
            "\n",
            "[20712 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "print(len(df[df['Name'].str.split().str[-1].str.startswith('R')]))\n",
        "print(df[df['Name'].str.split().str[-1].str.startswith('R')])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZtSIPM1Pe7u"
      },
      "source": [
        "### 78. Select the rows 2 to 7 and the columns 3 to 7 (both included)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "TOb6T1OfPe7u",
        "outputId": "ed8332d8-2aa2-49f7-d3cd-48e9ea64861c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Employee_City      Employee_Country  Employee_Salary Employment_Status  \\\n",
            "2        Wardfort              Anguilla         630890.0         Full Time   \n",
            "3  West Jamesview  Syrian Arab Republic         116400.0         Full Time   \n",
            "4       Whiteside              Dominica         523499.0         Full Time   \n",
            "5    Ricardomouth                  Mali         850140.0         Full Time   \n",
            "6        Wardfort                 Aruba         711410.0         Full Time   \n",
            "7     Kristaburgh        Western Sahara         777000.0         Full Time   \n",
            "\n",
            "   Employee_Rating  \n",
            "2              3.1  \n",
            "3              3.1  \n",
            "4              4.8  \n",
            "5              2.6  \n",
            "6              2.0  \n",
            "7              3.3  \n"
          ]
        }
      ],
      "source": [
        "print(df.iloc[2:8, 3:8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syW_Y1NYPe7u"
      },
      "source": [
        "### 79. Select every row after the 10th row and select all columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "gQh5Uh6fPe7u",
        "outputId": "7eb7d766-1b66-4ada-b8fc-be18187cc619"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   Name                    Company_Name  \\\n",
            "10      Victoria Sutton         White, Mcclain and Cobb   \n",
            "11      Timothy Johnson        Baker, Allen and Edwards   \n",
            "12       Tiffany Galvan  Campos, Reynolds and Mccormick   \n",
            "13          David Duran                   Nichols-James   \n",
            "14           Julie Cook                    Matthews Inc   \n",
            "...                 ...                             ...   \n",
            "299995       Nancy Neal                Bullock-Carrillo   \n",
            "299996   Michele Butler    Johnston, Fleming and Tanner   \n",
            "299997      Lynn Wilson                   Nichols-James   \n",
            "299998    Lindsey Keith                   Nichols-James   \n",
            "299999    Karen Delgado                  James and Sons   \n",
            "\n",
            "                             Employee_Job_Title      Employee_City  \\\n",
            "10                              Naval architect          Whiteside   \n",
            "11                   Regulatory affairs officer       Ricardomouth   \n",
            "12      Diplomatic Services operational officer     West Jamesview   \n",
            "13                 Investment banker, corporate     New Russellton   \n",
            "14                              Equities trader     New Russellton   \n",
            "...                                         ...                ...   \n",
            "299995                              Optometrist  North Melissafurt   \n",
            "299996                            Administrator         Aliciafort   \n",
            "299997                            Administrator   New Cindychester   \n",
            "299998                                     Make       Whitakerbury   \n",
            "299999                                  Actuary     New Russellton   \n",
            "\n",
            "       Employee_Country  Employee_Salary Employment_Status  Employee_Rating  \n",
            "10               Poland         656260.0         Full Time              4.9  \n",
            "11              Georgia         503610.0         Full Time              2.9  \n",
            "12                Niger         786430.0            Intern              3.6  \n",
            "13              Georgia         910210.0         Full Time              4.9  \n",
            "14          Puerto Rico         328860.0         Full Time              4.8  \n",
            "...                 ...              ...               ...              ...  \n",
            "299995            Samoa          99670.0            Intern              3.3  \n",
            "299996             Cuba         949580.0            Intern              2.6  \n",
            "299997          Bolivia         802830.0         Full Time              0.6  \n",
            "299998   Western Sahara         257240.0         Full Time              2.4  \n",
            "299999   United Kingdom         575770.0            Intern              3.3  \n",
            "\n",
            "[299990 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df.iloc[10:,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hwy-ERDPe7v"
      },
      "source": [
        "### 83. Print the name of the company with the maximum employees having rating > 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "NsA3RrBfPe7v",
        "outputId": "7327d64e-3cc0-47e8-c5c6-62549879e853"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matthews Inc\n"
          ]
        }
      ],
      "source": [
        "print(df[df['Employee_Rating'] > 4.0 ]['Company_Name'].value_counts().index[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKgaAnx4Pe7v"
      },
      "source": [
        "### 88. Which is the most common first name in the dataframe?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "QqECvk_hPe7v",
        "outputId": "cabb2a23-39e8-4596-ef66-96d78f18076f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Michael\n"
          ]
        }
      ],
      "source": [
        "print(df['Name'].str.split().str[0].value_counts().index[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNkCgUBPPe7w"
      },
      "source": [
        "### 90. What is the average name length?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "p8FEbitWPe7w",
        "outputId": "36196b79-5f95-46e0-a992-9d01d5bd885d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13.1079\n"
          ]
        }
      ],
      "source": [
        "print(df['Name'].str.len().mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcXYo3iCPe7w"
      },
      "source": [
        "# Pandas Notebook 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcTcKEiNPe7w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "6y8q-7ecPe7x",
        "outputId": "f22f68aa-0b8f-4778-bfb1-f902f48f37f5"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"input_data/employee_dataset.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uwpv8QQPe7x"
      },
      "source": [
        "### 91. What is the ratio of total full-time employees to Interns?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "VlHgfIl8Pe7x",
        "outputId": "6a5d720a-8725-478d-afa3-f8d113729082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.0008334722453744\n"
          ]
        }
      ],
      "source": [
        "print(len(df[df['Employment_Status']=='Full Time'])/len(df[df['Employment_Status']=='Intern']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_ZnTPK2Pe7x"
      },
      "source": [
        "### 92. Starting from the first record, print every third record in the DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmL3VdqYPe7y"
      },
      "source": [
        "Print 1st row, then 4th, 7th, 10th, and so on..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "zetfxJSbPe7y",
        "outputId": "1c4417f4-a410-4eae-ef37-4fed904ff2c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   Name              Company_Name  \\\n",
            "1          Julie Morton             Nichols-James   \n",
            "4         Theresa Owens  Baker, Allen and Edwards   \n",
            "7           Vicki Beard              Matthews Inc   \n",
            "10      Victoria Sutton   White, Mcclain and Cobb   \n",
            "13          David Duran             Nichols-James   \n",
            "...                 ...                       ...   \n",
            "299986      Chelsea Lee               Andrade LLC   \n",
            "299989   Deborah Berger            James and Sons   \n",
            "299992  Steven Thornton  Baker, Allen and Edwards   \n",
            "299995       Nancy Neal          Bullock-Carrillo   \n",
            "299998    Lindsey Keith             Nichols-James   \n",
            "\n",
            "                             Employee_Job_Title      Employee_City  \\\n",
            "1       Diplomatic Services operational officer  North Melissafurt   \n",
            "4                           Production engineer          Whiteside   \n",
            "7       Diplomatic Services operational officer        Kristaburgh   \n",
            "10                              Naval architect          Whiteside   \n",
            "13                 Investment banker, corporate     New Russellton   \n",
            "...                                         ...                ...   \n",
            "299986             Investment banker, corporate           Wardfort   \n",
            "299989        Sales promotion account executive   New Cindychester   \n",
            "299992                          Patent examiner         Aliciafort   \n",
            "299995                              Optometrist  North Melissafurt   \n",
            "299998                                     Make       Whitakerbury   \n",
            "\n",
            "        Employee_Country  Employee_Salary Employment_Status  Employee_Rating  \n",
            "1       Marshall Islands           589090         Full Time              4.3  \n",
            "4               Dominica           523499         Full Time              4.8  \n",
            "7         Western Sahara           777000         Full Time              3.3  \n",
            "10                Poland           656260         Full Time              4.9  \n",
            "13               Georgia           910210         Full Time              4.9  \n",
            "...                  ...              ...               ...              ...  \n",
            "299986       Switzerland            88410         Full Time              4.4  \n",
            "299989             Malta           285660         Full Time              3.1  \n",
            "299992             Benin            60240         Full Time              4.3  \n",
            "299995             Samoa            99670            Intern              3.3  \n",
            "299998    Western Sahara           257240         Full Time              2.4  \n",
            "\n",
            "[100000 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "### 92. Starting from the first record, print every third record in the DataFrame.\n",
        "print(df.iloc[1::3,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEIHS5YzPe7y"
      },
      "source": [
        "### 93. Find the average salary for every company."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXDyK9zpPe7y",
        "outputId": "c1ccfcb2-5cc7-4e3a-c50b-7feb03b4a943"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Company_Name\n",
              "Andrade LLC                       497237.159385\n",
              "Baker, Allen and Edwards          498032.358445\n",
              "Bullock-Carrillo                  499603.804865\n",
              "Campos, Reynolds and Mccormick    503528.982687\n",
              "James and Sons                    503581.015754\n",
              "Johnston, Fleming and Tanner      500579.128010\n",
              "Marshall-Holloway                 502314.169445\n",
              "Matthews Inc                      501640.159488\n",
              "Nelson-Li                         500569.824558\n",
              "Nichols-James                     497881.232334\n",
              "Scott Inc                         500491.809024\n",
              "Taylor-Ramos                      498747.292516\n",
              "Thomas-Spencer                    499350.850164\n",
              "Wallace, Smith and Shepard        500807.608810\n",
              "White, Mcclain and Cobb           499083.493806\n",
              "Name: Employee_Salary, dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(df.groupby('Company_Name')['Employee_Salary'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JDfHAIIPe7y"
      },
      "source": [
        "### 95. Find the average salary and average rating for every company in a single line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "Nrg4uySPPe7z",
        "outputId": "c5436c1d-9f1d-4726-fd29-17b6d4a32f00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                Employee_Salary  Employee_Rating\n",
            "Company_Name                                                    \n",
            "Andrade LLC                       497237.159385         2.498218\n",
            "Baker, Allen and Edwards          498032.358445         2.504795\n",
            "Bullock-Carrillo                  499603.804865         2.502014\n",
            "Campos, Reynolds and Mccormick    503528.982687         2.506288\n",
            "James and Sons                    503581.015754         2.505023\n",
            "Johnston, Fleming and Tanner      500579.128010         2.513159\n",
            "Marshall-Holloway                 502314.169445         2.504900\n",
            "Matthews Inc                      501640.159488         2.525454\n",
            "Nelson-Li                         500569.824558         2.504649\n",
            "Nichols-James                     497881.232334         2.488554\n",
            "Scott Inc                         500491.809024         2.515993\n",
            "Taylor-Ramos                      498747.292516         2.513150\n",
            "Thomas-Spencer                    499350.850164         2.505114\n",
            "Wallace, Smith and Shepard        500807.608810         2.497402\n",
            "White, Mcclain and Cobb           499083.493806         2.504047\n"
          ]
        }
      ],
      "source": [
        "print(df.groupby('Company_Name')[['Employee_Salary', 'Employee_Rating']].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2VHx3CnPe7z"
      },
      "source": [
        "### 96. Find the number of unique Employee_City corresponding to every Company_Name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "XgsJfd2jPe7z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Company_Name\n",
            "Andrade LLC                       10\n",
            "Baker, Allen and Edwards          10\n",
            "Bullock-Carrillo                  10\n",
            "Campos, Reynolds and Mccormick    10\n",
            "James and Sons                    10\n",
            "Johnston, Fleming and Tanner      10\n",
            "Marshall-Holloway                 10\n",
            "Matthews Inc                      10\n",
            "Nelson-Li                         10\n",
            "Nichols-James                     10\n",
            "Scott Inc                         10\n",
            "Taylor-Ramos                      10\n",
            "Thomas-Spencer                    10\n",
            "Wallace, Smith and Shepard        10\n",
            "White, Mcclain and Cobb           10\n",
            "Name: Employee_City, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.groupby('Company_Name')['Employee_City'].nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VvbGXqlPe70"
      },
      "source": [
        "### 98. Print the number of full-time and intern employees for every company"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "Gln5msczPe70",
        "outputId": "253b73aa-c578-4c89-f935-33689adbce10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Company_Name                    Employment_Status\n",
            "Andrade LLC                     Full Time            15964\n",
            "                                Intern                4019\n",
            "Baker, Allen and Edwards        Full Time            16118\n",
            "                                Intern                3966\n",
            "Bullock-Carrillo                Full Time            16135\n",
            "                                Intern                3928\n",
            "Campos, Reynolds and Mccormick  Full Time            15930\n",
            "                                Intern                3997\n",
            "James and Sons                  Full Time            15888\n",
            "                                Intern                3980\n",
            "Johnston, Fleming and Tanner    Full Time            15832\n",
            "                                Intern                3979\n",
            "Marshall-Holloway               Full Time            15871\n",
            "                                Intern                3988\n",
            "Matthews Inc                    Full Time            16082\n",
            "                                Intern                4001\n",
            "Nelson-Li                       Full Time            16027\n",
            "                                Intern                4105\n",
            "Nichols-James                   Full Time            15872\n",
            "                                Intern                4039\n",
            "Scott Inc                       Full Time            16396\n",
            "                                Intern                3994\n",
            "Taylor-Ramos                    Full Time            16086\n",
            "                                Intern                4036\n",
            "Thomas-Spencer                  Full Time            16037\n",
            "                                Intern                4105\n",
            "Wallace, Smith and Shepard      Full Time            15467\n",
            "                                Intern                3897\n",
            "White, Mcclain and Cobb         Full Time            16305\n",
            "                                Intern                3956\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.groupby('Company_Name')['Employment_Status'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngQliglUPe70"
      },
      "source": [
        "### 99. Print the job title with the most employees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "zKOcaxGhPe70",
        "outputId": "e4bcfa80-e62e-4ea5-93f2-c0ef98b3b8b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diplomatic Services operational officer\n"
          ]
        }
      ],
      "source": [
        "print(df['Employee_Job_Title'].value_counts().index[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa-4WcqRPe70"
      },
      "source": [
        "### 107. Check if the substring 'Michael Edward' appears in the Name column or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "-Z4xky-rPe71",
        "outputId": "a7c7147c-ad27-4ccd-e7c6-a4fbbaaa4100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0         False\n",
            "1         False\n",
            "2         False\n",
            "3         False\n",
            "4         False\n",
            "          ...  \n",
            "299995    False\n",
            "299996    False\n",
            "299997    False\n",
            "299998    False\n",
            "299999    False\n",
            "Name: Name, Length: 300000, dtype: bool\n"
          ]
        }
      ],
      "source": [
        "print(df['Name'].str.contains('Michael Edward'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFvkiETQPe71"
      },
      "source": [
        "### 110. Print the number of records whose company name contains the substring 'LL' (case-insensitive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "N3o9cFLRPe71",
        "outputId": "e0081780-c51c-4163-9198-13dd385a43fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   Name                Company_Name  \\\n",
            "4         Theresa Owens    Baker, Allen and Edwards   \n",
            "5         Vanessa Allen                 Andrade LLC   \n",
            "6           Kelly Brown                 Andrade LLC   \n",
            "11      Timothy Johnson    Baker, Allen and Edwards   \n",
            "18         Carrie Woods            Bullock-Carrillo   \n",
            "...                 ...                         ...   \n",
            "299977   Anthony Hughes            Bullock-Carrillo   \n",
            "299986      Chelsea Lee                 Andrade LLC   \n",
            "299990    Monica Bender  Wallace, Smith and Shepard   \n",
            "299992  Steven Thornton    Baker, Allen and Edwards   \n",
            "299995       Nancy Neal            Bullock-Carrillo   \n",
            "\n",
            "                       Employee_Job_Title      Employee_City Employee_Country  \\\n",
            "4                     Production engineer          Whiteside         Dominica   \n",
            "5                                    Make       Ricardomouth             Mali   \n",
            "6                         Naval architect           Wardfort            Aruba   \n",
            "11             Regulatory affairs officer       Ricardomouth          Georgia   \n",
            "18                             Ergonomist     New Russellton            Gabon   \n",
            "...                                   ...                ...              ...   \n",
            "299977  Sales promotion account executive       Whitakerbury          Georgia   \n",
            "299986       Investment banker, corporate           Wardfort      Switzerland   \n",
            "299990                Production engineer   New Cindychester       Bangladesh   \n",
            "299992                    Patent examiner         Aliciafort            Benin   \n",
            "299995                        Optometrist  North Melissafurt            Samoa   \n",
            "\n",
            "        Employee_Salary Employment_Status  Employee_Rating  \n",
            "4                523499         Full Time              4.8  \n",
            "5                850140         Full Time              2.6  \n",
            "6                711410         Full Time              2.0  \n",
            "11               503610         Full Time              2.9  \n",
            "18               985290         Full Time              2.4  \n",
            "...                 ...               ...              ...  \n",
            "299977           464910         Full Time              4.1  \n",
            "299986            88410         Full Time              4.4  \n",
            "299990           852660         Full Time              3.0  \n",
            "299992            60240         Full Time              4.3  \n",
            "299995            99670            Intern              3.3  \n",
            "\n",
            "[99353 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "### 110. Print the number of records whose company name contains the substring 'LL' (case-insensitive).\n",
        "print(df[df['Company_Name'].str.contains('LL', case=False)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZP6lYrDPe71"
      },
      "source": [
        "### 111. Select the first row corresponding to every company in the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "rXcmTisoPe71",
        "outputId": "d7a3e88f-c294-4db1-989b-a2cae47526fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              Name  \\\n",
            "Company_Name                                         \n",
            "Andrade LLC                          Vanessa Allen   \n",
            "Baker, Allen and Edwards             Theresa Owens   \n",
            "Bullock-Carrillo                      Carrie Woods   \n",
            "Campos, Reynolds and Mccormick     Michael Edwards   \n",
            "James and Sons                      Spencer Adkins   \n",
            "Johnston, Fleming and Tanner            Brad Scott   \n",
            "Marshall-Holloway                   David Phillips   \n",
            "Matthews Inc                           Vicki Beard   \n",
            "Nelson-Li                       Micheal Fitzgerald   \n",
            "Nichols-James                         Julie Morton   \n",
            "Scott Inc                             Matthew Hall   \n",
            "Taylor-Ramos                           Lisa French   \n",
            "Thomas-Spencer                           Gail Rose   \n",
            "Wallace, Smith and Shepard            Ronald Clark   \n",
            "White, Mcclain and Cobb            Victoria Sutton   \n",
            "\n",
            "                                                     Employee_Job_Title  \\\n",
            "Company_Name                                                              \n",
            "Andrade LLC                                                        Make   \n",
            "Baker, Allen and Edwards                            Production engineer   \n",
            "Bullock-Carrillo                                             Ergonomist   \n",
            "Campos, Reynolds and Mccormick                               Ergonomist   \n",
            "James and Sons                                          Equities trader   \n",
            "Johnston, Fleming and Tanner                        Production engineer   \n",
            "Marshall-Holloway                             Radiographer, therapeutic   \n",
            "Matthews Inc                    Diplomatic Services operational officer   \n",
            "Nelson-Li                       Diplomatic Services operational officer   \n",
            "Nichols-James                   Diplomatic Services operational officer   \n",
            "Scott Inc                                    Regulatory affairs officer   \n",
            "Taylor-Ramos                                  Radiographer, therapeutic   \n",
            "Thomas-Spencer                                          Patent examiner   \n",
            "Wallace, Smith and Shepard                   Regulatory affairs officer   \n",
            "White, Mcclain and Cobb                                 Naval architect   \n",
            "\n",
            "                                    Employee_City  \\\n",
            "Company_Name                                        \n",
            "Andrade LLC                          Ricardomouth   \n",
            "Baker, Allen and Edwards                Whiteside   \n",
            "Bullock-Carrillo                   New Russellton   \n",
            "Campos, Reynolds and Mccormick   New Cindychester   \n",
            "James and Sons                     New Russellton   \n",
            "Johnston, Fleming and Tanner       West Jamesview   \n",
            "Marshall-Holloway                     Kristaburgh   \n",
            "Matthews Inc                          Kristaburgh   \n",
            "Nelson-Li                            Whitakerbury   \n",
            "Nichols-James                   North Melissafurt   \n",
            "Scott Inc                                Wardfort   \n",
            "Taylor-Ramos                       West Jamesview   \n",
            "Thomas-Spencer                       Whitakerbury   \n",
            "Wallace, Smith and Shepard      North Melissafurt   \n",
            "White, Mcclain and Cobb                 Whiteside   \n",
            "\n",
            "                                                Employee_Country  \\\n",
            "Company_Name                                                       \n",
            "Andrade LLC                                                 Mali   \n",
            "Baker, Allen and Edwards                                Dominica   \n",
            "Bullock-Carrillo                                           Gabon   \n",
            "Campos, Reynolds and Mccormick  Lao People's Democratic Republic   \n",
            "James and Sons                             Palestinian Territory   \n",
            "Johnston, Fleming and Tanner                Syrian Arab Republic   \n",
            "Marshall-Holloway                         British Virgin Islands   \n",
            "Matthews Inc                                      Western Sahara   \n",
            "Nelson-Li                                            Switzerland   \n",
            "Nichols-James                                   Marshall Islands   \n",
            "Scott Inc                                               Anguilla   \n",
            "Taylor-Ramos                                              Kuwait   \n",
            "Thomas-Spencer                                           Finland   \n",
            "Wallace, Smith and Shepard                                 Palau   \n",
            "White, Mcclain and Cobb                                   Poland   \n",
            "\n",
            "                                Employee_Salary Employment_Status  \\\n",
            "Company_Name                                                        \n",
            "Andrade LLC                              850140         Full Time   \n",
            "Baker, Allen and Edwards                 523499         Full Time   \n",
            "Bullock-Carrillo                         985290         Full Time   \n",
            "Campos, Reynolds and Mccormick           516950         Full Time   \n",
            "James and Sons                           321520         Full Time   \n",
            "Johnston, Fleming and Tanner             116400         Full Time   \n",
            "Marshall-Holloway                         58800         Full Time   \n",
            "Matthews Inc                             777000         Full Time   \n",
            "Nelson-Li                                796690         Full Time   \n",
            "Nichols-James                            589090         Full Time   \n",
            "Scott Inc                                630890         Full Time   \n",
            "Taylor-Ramos                             870580         Full Time   \n",
            "Thomas-Spencer                           178570         Full Time   \n",
            "Wallace, Smith and Shepard               914110         Full Time   \n",
            "White, Mcclain and Cobb                  656260         Full Time   \n",
            "\n",
            "                                Employee_Rating  \n",
            "Company_Name                                     \n",
            "Andrade LLC                                 2.6  \n",
            "Baker, Allen and Edwards                    4.8  \n",
            "Bullock-Carrillo                            2.4  \n",
            "Campos, Reynolds and Mccormick              2.3  \n",
            "James and Sons                              3.9  \n",
            "Johnston, Fleming and Tanner                3.1  \n",
            "Marshall-Holloway                           0.6  \n",
            "Matthews Inc                                3.3  \n",
            "Nelson-Li                                   4.1  \n",
            "Nichols-James                               4.3  \n",
            "Scott Inc                                   3.1  \n",
            "Taylor-Ramos                                1.3  \n",
            "Thomas-Spencer                              1.9  \n",
            "Wallace, Smith and Shepard                  3.2  \n",
            "White, Mcclain and Cobb                     4.9  \n"
          ]
        }
      ],
      "source": [
        "print(df.groupby('Company_Name').first())\n",
        "\n",
        "#first(), last(), nth()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8QP7Vo5Pe72"
      },
      "source": [
        "### 113. Reset the index of the dataframe inplace and delete the older index values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "pd4HD_60Pe72",
        "outputId": "09594bed-d803-43e5-e9b1-bedbe852baf8"
      },
      "outputs": [],
      "source": [
        "### 113. Reset the index of the dataframe inplace and delete the older index values.\n",
        "df.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6hjV2BpPe72"
      },
      "source": [
        "### 115-1) Add a new row at the bottom of the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "24Sd0u3TPe72",
        "outputId": "902695c8-84eb-4ed8-85a0-5a87ccc363a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  Name                  Company_Name  \\\n",
            "0       Spencer Adkins                James and Sons   \n",
            "1         Julie Morton                 Nichols-James   \n",
            "2         Matthew Hall                     Scott Inc   \n",
            "3           Brad Scott  Johnston, Fleming and Tanner   \n",
            "4        Theresa Owens      Baker, Allen and Edwards   \n",
            "...                ...                           ...   \n",
            "299997     Lynn Wilson                 Nichols-James   \n",
            "299998   Lindsey Keith                 Nichols-James   \n",
            "299999   Karen Delgado                James and Sons   \n",
            "300001    Chris Anders                     Scott Inc   \n",
            "300000    Chris Anders                     Scott Inc   \n",
            "\n",
            "                             Employee_Job_Title      Employee_City  \\\n",
            "0                               Equities trader     New Russellton   \n",
            "1       Diplomatic Services operational officer  North Melissafurt   \n",
            "2                    Regulatory affairs officer           Wardfort   \n",
            "3                           Production engineer     West Jamesview   \n",
            "4                           Production engineer          Whiteside   \n",
            "...                                         ...                ...   \n",
            "299997                            Administrator   New Cindychester   \n",
            "299998                                     Make       Whitakerbury   \n",
            "299999                                  Actuary     New Russellton   \n",
            "300001                      Production engineer           Wardfort   \n",
            "300000                      Production engineer           Wardfort   \n",
            "\n",
            "             Employee_Country  Employee_Salary Employment_Status  \\\n",
            "0       Palestinian Territory           321520         Full Time   \n",
            "1            Marshall Islands           589090         Full Time   \n",
            "2                    Anguilla           630890         Full Time   \n",
            "3        Syrian Arab Republic           116400         Full Time   \n",
            "4                    Dominica           523499         Full Time   \n",
            "...                       ...              ...               ...   \n",
            "299997                Bolivia           802830         Full Time   \n",
            "299998         Western Sahara           257240         Full Time   \n",
            "299999         United Kingdom           575770            Intern   \n",
            "300001               Anguilla           343930         Full Time   \n",
            "300000               Anguilla           343930         Full Time   \n",
            "\n",
            "        Employee_Rating  \n",
            "0                   3.9  \n",
            "1                   4.3  \n",
            "2                   3.1  \n",
            "3                   3.1  \n",
            "4                   4.8  \n",
            "...                 ...  \n",
            "299997              0.6  \n",
            "299998              2.4  \n",
            "299999              3.3  \n",
            "300001              3.3  \n",
            "300000              3.3  \n",
            "\n",
            "[300002 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "### 115-1) Add a new row at the bottom of the DataFrame. with 300001\tChris Anders\tScott Inc\tProduction engineer\tWardfort\tAnguilla\t343930\tFull Time\t3.3 and print\n",
        "df.loc[300000] = ['Chris Anders', 'Scott Inc', 'Production engineer', 'Wardfort', 'Anguilla', 343930, 'Full Time', 3.3]\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMmbfUv9Pe73"
      },
      "source": [
        "### 115-2) Delete the row that was just newly added."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "TLQxXlx0Pe73",
        "outputId": "9adec665-a7d6-41f2-a3a2-80e064ec369b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  Name                  Company_Name  \\\n",
            "0       Spencer Adkins                James and Sons   \n",
            "1         Julie Morton                 Nichols-James   \n",
            "2         Matthew Hall                     Scott Inc   \n",
            "3           Brad Scott  Johnston, Fleming and Tanner   \n",
            "4        Theresa Owens      Baker, Allen and Edwards   \n",
            "...                ...                           ...   \n",
            "299996  Michele Butler  Johnston, Fleming and Tanner   \n",
            "299997     Lynn Wilson                 Nichols-James   \n",
            "299998   Lindsey Keith                 Nichols-James   \n",
            "299999   Karen Delgado                James and Sons   \n",
            "300000    Chris Anders                     Scott Inc   \n",
            "\n",
            "                             Employee_Job_Title      Employee_City  \\\n",
            "0                               Equities trader     New Russellton   \n",
            "1       Diplomatic Services operational officer  North Melissafurt   \n",
            "2                    Regulatory affairs officer           Wardfort   \n",
            "3                           Production engineer     West Jamesview   \n",
            "4                           Production engineer          Whiteside   \n",
            "...                                         ...                ...   \n",
            "299996                            Administrator         Aliciafort   \n",
            "299997                            Administrator   New Cindychester   \n",
            "299998                                     Make       Whitakerbury   \n",
            "299999                                  Actuary     New Russellton   \n",
            "300000                      Production engineer           Wardfort   \n",
            "\n",
            "             Employee_Country  Employee_Salary Employment_Status  \\\n",
            "0       Palestinian Territory           321520         Full Time   \n",
            "1            Marshall Islands           589090         Full Time   \n",
            "2                    Anguilla           630890         Full Time   \n",
            "3        Syrian Arab Republic           116400         Full Time   \n",
            "4                    Dominica           523499         Full Time   \n",
            "...                       ...              ...               ...   \n",
            "299996                   Cuba           949580            Intern   \n",
            "299997                Bolivia           802830         Full Time   \n",
            "299998         Western Sahara           257240         Full Time   \n",
            "299999         United Kingdom           575770            Intern   \n",
            "300000               Anguilla           343930         Full Time   \n",
            "\n",
            "        Employee_Rating  \n",
            "0                   3.9  \n",
            "1                   4.3  \n",
            "2                   3.1  \n",
            "3                   3.1  \n",
            "4                   4.8  \n",
            "...                 ...  \n",
            "299996              2.6  \n",
            "299997              0.6  \n",
            "299998              2.4  \n",
            "299999              3.3  \n",
            "300000              3.3  \n",
            "\n",
            "[300001 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "### 115-2) Delete the row that was just newly added.\n",
        "df.drop(300001, inplace=True)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j397D96QPe73"
      },
      "source": [
        "### 117. Add a new column \"Employee_Rating_New\" which should be as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCmW_CxrPe73"
      },
      "source": [
        "Employee_Rating_New = max(1.5, 2*Employee_Rating - 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "HabxS2nEPe73"
      },
      "outputs": [],
      "source": [
        "df['Employee_Rating_New'] = df['Employee_Rating'].apply(lambda x: max(1.5, 2*x - 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDBjDQmZPe74"
      },
      "source": [
        "### 118. Convert the entire DataFrame to a list of lists. Do NOT overwrite to the current dataframe object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "1gQNp9XxPe74"
      },
      "outputs": [],
      "source": [
        "### 118. Convert the entire DataFrame to a list of lists. Do NOT overwrite to the current dataframe object.\n",
        "df_list = df.values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX4apTHYPe74"
      },
      "source": [
        "### 120. Rearrange the columns in the below order. Overwrite to the current DataFrame object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "GiSuCB1pPe74"
      },
      "outputs": [],
      "source": [
        "new_order = [\"Name\", \"Employee_Job_Title\", \"Company_Name\",\n",
        "             \"Employee_City\", \"Employee_Country\", \"Employment_Status\",\n",
        "             \"Employee_Salary\", \"Employee_Rating\", \"Employee_Rating_New\"]\n",
        "df_list = df[new_order].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zeaEu2DPe74"
      },
      "source": [
        "### 123. Drop the 'Name' column inplace from the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "7RQLt4ARPe75",
        "outputId": "69b04cfa-2c3b-43c8-e0a9-2b433b0a25bd"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['Name'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[208], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5260\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5264\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5265\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:6696\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6695\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6696\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6697\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
            "\u001b[1;31mKeyError\u001b[0m: \"['Name'] not found in axis\""
          ]
        }
      ],
      "source": [
        "df.drop('Name', axis=1, inplace=True)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myepx0x9Pe75"
      },
      "source": [
        "### 126. Rename the columns and store to a new DataFrame 'df_renamed':"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deGE3auXPe75"
      },
      "source": [
        "1. Employee_Rating -> Rating\n",
        "2. Employee_Country -> Country\n",
        "3. Employee_Salary -> Salary\n",
        "4. Employee_Rating_New -> Rating_New\n",
        "5. Employment_Status -> Employment_type\n",
        "6. Employment_City -> City"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "eK9nSJiHPe75"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_renamed = df.rename(columns={'Employee_Rating': 'Rating', 'Employee_Country': 'Country', 'Employee_Salary': 'Salary', 'Employee_Rating_New': 'Rating_New', 'Employment_Status': 'Employment_type', 'Employee_City': 'City'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhM7zYBePe76"
      },
      "source": [
        "### 128. Count the number of NaN values in each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "-OIBONVHPe76",
        "outputId": "e4f48e31-faf5-43ad-cce0-40078b3c8598"
      },
      "outputs": [],
      "source": [
        "### 128. Count the number of NaN values in each column\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmwv-BkePe76"
      },
      "source": [
        "### 131.  Map every Company_Name to a unique integer value. Name the new column \"Company_ID\".  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOk--optPe76"
      },
      "source": [
        "For instance, if the data has 5 companies, \"Company A\" -> 1, \"Company B\" -> 2, \"Company C\" -> 3, \"Company D\" -> 4, \"Company E\" -> 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaoXRKB_Pe77"
      },
      "outputs": [],
      "source": [
        "df['Company_ID'] = df['Company_Name'].astype('category').cat.codes+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgXvWQrsPe77"
      },
      "source": [
        "### 133. Print the number of rows where 'City' belongs to the following list of cities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfLlVniSPe77"
      },
      "source": [
        "Use the isin() method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7hJfEGoPe77",
        "outputId": "1de1f4e0-cb9e-4271-a69b-d9abb9bd98d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90054\n"
          ]
        }
      ],
      "source": [
        "city_filter_list = [\"New Russellton\", \"Whiteside\", \"Kristaburgh\"]\n",
        "\n",
        "row_count = len(df[df['Employee_City'].isin(city_filter_list)])\n",
        "print(row_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWaTfVdzPe77"
      },
      "source": [
        "### 135. Print the name of the person with the 10th largest salary. If there are multiple people with the same salary, print all names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf_k7gPOPe78",
        "outputId": "f2adfc10-959c-4d43-ce8b-02390212e423"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Allen Chavez', 'David Ryan', 'Elizabeth Bell', 'Megan Petersen'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(df.sort_values(by='Employee_Salary', ascending=False)['Name'].unique()[9])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBkKlLHIPe78"
      },
      "source": [
        "### 136. Print a cross tabulation of Company Name and Employment Type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRkwdkPbPe78",
        "outputId": "c40423eb-c86d-47f3-d5e3-e548063e5744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Employment_Status               Full Time  Intern\n",
            "Company_Name                                     \n",
            "Andrade LLC                         15964    4019\n",
            "Baker, Allen and Edwards            16118    3966\n",
            "Bullock-Carrillo                    16135    3928\n",
            "Campos, Reynolds and Mccormick      15930    3997\n",
            "James and Sons                      15888    3980\n",
            "Johnston, Fleming and Tanner        15832    3979\n",
            "Marshall-Holloway                   15871    3988\n",
            "Matthews Inc                        16082    4001\n",
            "Nelson-Li                           16027    4105\n",
            "Nichols-James                       15872    4039\n",
            "Scott Inc                           16396    3994\n",
            "Taylor-Ramos                        16086    4036\n",
            "Thomas-Spencer                      16037    4105\n",
            "Wallace, Smith and Shepard          15467    3897\n",
            "White, Mcclain and Cobb             16305    3956\n"
          ]
        }
      ],
      "source": [
        "print(pd.crosstab(df['Company_Name'], df['Employment_Status']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrM0r91NPe78"
      },
      "source": [
        "### 143-145. Print the 25th, 50th and 75th percentile of the Salary column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljZc-1O1Pe78",
        "outputId": "44bd1fcc-a6a6-4981-b699-059ad38091c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25%    250000.0\n",
              "50%    500780.0\n",
              "75%    749710.0\n",
              "Name: Employee_Salary, dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(df['Employee_Salary'].quantile([0.25, 0.5, 0.75]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TL8a8tUPe79"
      },
      "source": [
        "### 147. Distribute the Salary column in 10 equal sized bins and label each bin from 1 to 10 and add a new column named \"Labels\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrbC-VNUPe79"
      },
      "outputs": [],
      "source": [
        "df['Labels'] = pd.qcut(df['Employee_Salary'], q=10, labels=range(1,11))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVe6rP-kPe79"
      },
      "source": [
        "# Pandas Notebook 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0Wbl2GQPe79"
      },
      "source": [
        "### 151. Sort DataFrame based on another list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBIbQltKPe79"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "QVMuIqR4Pe79",
        "outputId": "82b19342-c2dc-4c82-d8ae-0939b39a4f30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  col1  col2\n",
            "0    A     1\n",
            "1    B     2\n",
            "2    C     3\n",
            "3    D     4\n"
          ]
        }
      ],
      "source": [
        "new_df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
        "                   [\"C\", 3], [\"D\", 4]], columns=[\"col1\", \"col2\"])\n",
        "\n",
        "sort_list = [\"C\", \"A\", \"D\", \"B\"]\n",
        "\n",
        "# start your code below\n",
        "\n",
        "new_df['col1'] = df['col1'].astype('category')\n",
        "\n",
        "\n",
        "# end your code here\n",
        "print(new_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOMXwrxgPe7-"
      },
      "source": [
        "### 152. Insert a column at a specific location in a DataFrame with a name, \"new_column\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XByXiC12Pe7-",
        "outputId": "63b744c4-3f5b-4512-fb3f-5514f91368ad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_A</th>\n",
              "      <th>new_column</th>\n",
              "      <th>col_B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B</td>\n",
              "      <td>Q</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C</td>\n",
              "      <td>R</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D</td>\n",
              "      <td>S</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  col_A new_column  col_B\n",
              "0     A          P      1\n",
              "1     B          Q      2\n",
              "2     C          R      3\n",
              "3     D          S      4"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
        "                   [\"C\", 3], [\"D\", 4]],\n",
        "                  columns=[\"col_A\", \"col_B\"])\n",
        "\n",
        "new_column = [\"P\", \"Q\", \"R\", \"S\"]\n",
        "insert_position = 1 ## between col_A and col_B\n",
        "\n",
        "## start your code below\n",
        "df.insert(insert_position, 'new_column', new_column)\n",
        "\n",
        "\n",
        "## end your code here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3shGNnyzPe7-"
      },
      "source": [
        "### 154. Count the number of Non-NaN cells for each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHuyZYDUPe7-"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWws51PzPe7_",
        "outputId": "108b534a-f139-40e2-dc35-e3adfa47223f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "col_A    3\n",
              "col_B    2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.DataFrame([[\"A\", np.NaN], [np.NaN, 2],\n",
        "                   [\"C\", np.NaN], [\"D\", 4]],\n",
        "                  columns=[\"col_A\", \"col_B\"])\n",
        "\n",
        "## start your code below\n",
        "print(df.count())\n",
        "\n",
        "\n",
        "## end your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJLDTWytPe7_"
      },
      "source": [
        "### 156. Reverse DataFrame row-wise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dp5oaekgPe7_",
        "outputId": "588e4ae2-8605-4960-fe63-d4fb7f8db47a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_A</th>\n",
              "      <th>col_B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  col_A  col_B\n",
              "3     D      4\n",
              "2     C      3\n",
              "1     B      2\n",
              "0     A      1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
        "                   [\"C\", 3], [\"D\", 4]],\n",
        "                  columns=[\"col_A\", \"col_B\"])\n",
        "\n",
        "## start your code below\n",
        "print(df[::-1])\n",
        "\n",
        "\n",
        "## end our code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU4_yh9QPe7_"
      },
      "source": [
        "### 157. Reverse DataFrame column-wise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1zbUlyuPe8A",
        "outputId": "0805cb05-18bd-4420-8480-c68c0a963b96"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_B</th>\n",
              "      <th>col_A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   col_B col_A\n",
              "0      1     A\n",
              "1      2     B\n",
              "2      3     C\n",
              "3      4     D"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
        "                   [\"C\", 3], [\"D\", 4]],\n",
        "                  columns=[\"col_A\", \"col_B\"])\n",
        "\n",
        "## start your code below\n",
        "print(df.loc[:, ::-1])\n",
        "\n",
        "## end your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5OmWLAaPe8A"
      },
      "source": [
        "### 158. Insert a row at an arbitrary position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpBYs6BaPe8A",
        "outputId": "597b3b56-a302-4c80-95f5-77d83b71cc8c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_A</th>\n",
              "      <th>col_B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>D</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  col_A  col_B\n",
              "0     A      1\n",
              "1     P      5\n",
              "2     B      2\n",
              "3     C      3\n",
              "4     D      4"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
        "                   [\"C\", 3], [\"D\", 4]],\n",
        "                  columns=[\"col_A\", \"col_B\"])\n",
        "\n",
        "insert_pos = 1\n",
        "insert_row = [\"P\", 5]\n",
        "\n",
        "## start your code below\n",
        "df = df.iloc[:, ::-1]\n",
        "\n",
        "## end your code here\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qrE1LqlPe8A"
      },
      "source": [
        "### 160. The cumulative sum of a column in DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "AQrSlracPe8B",
        "outputId": "888a1281-5eac-465f-e72d-473bb8d0dfe7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_A</th>\n",
              "      <th>col_B</th>\n",
              "      <th>cumulatedSume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  col_A  col_B  cumulatedSume\n",
              "0     A      1              1\n",
              "1     B      2              3\n",
              "2     C      3              6\n",
              "3     D      4             10"
            ]
          },
          "execution_count": 219,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
        "                   [\"C\", 3], [\"D\", 4]], columns=[\"col_A\", \"col_B\"])\n",
        "\n",
        "## start your code below\n",
        "### 160. The cumulative sum of a column in DataFrame add it as column!! \n",
        "df['cumulatedSume'] = df['col_B'].cumsum()\n",
        "## end your code here\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFw8wRDDPe8B"
      },
      "source": [
        "### 165. Filter n-largest values from a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "bUN5ZeDnPe8B",
        "outputId": "356b0ffb-b6cd-4819-b6b9-828f823ca190"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_A</th>\n",
              "      <th>col_B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  col_A  col_B\n",
              "1     B    400\n",
              "3     D    300"
            ]
          },
          "execution_count": 220,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame([[\"A\", 200], [\"B\", 400],\n",
        "                   [\"C\", 100], [\"D\", 300]],\n",
        "                  columns=[\"col_A\", \"col_B\"])\n",
        "\n",
        "k = 2\n",
        "\n",
        "## start your code below\n",
        "largest_k = df.nlargest(k, 'col_B')\n",
        "\n",
        "## end your code here\n",
        "\n",
        "largest_k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIUaA19sPe8C"
      },
      "source": [
        "### 169. Delete the rows that have NaN values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "PGDbUsNFPe8C",
        "outputId": "7ef6fbd2-54e9-4b80-9182-7de9c1117d40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  col_A  col_B\n",
            "1     B    2.0\n",
            "3     D    4.0\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame([[\"A\", np.NaN], [\"B\", 2],\n",
        "                   [\"C\", np.NaN], [\"D\", 4]],\n",
        "                  columns=[\"col_A\", \"col_B\"])\n",
        "\n",
        "## start your code below\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "\n",
        "## end your code here\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owHFel_vPe8C"
      },
      "source": [
        "### 171. Fill NaN values with column mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "id": "uXmoI6UDPe8C",
        "outputId": "fc58c397-1407-401a-bbbd-90041862f1e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  col_A  col_B\n",
            "0     A    3.0\n",
            "1     B    2.0\n",
            "2     C    3.0\n",
            "3     D    4.0\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame([[\"A\", np.NaN], [\"B\", 2],\n",
        "                   [\"C\", np.NaN], [\"D\", 4]],\n",
        "                  columns=[\"col_A\", \"col_B\"])\n",
        "\n",
        "## start your code below\n",
        "df['col_B'].fillna(df['col_B'].mean(), inplace=True)\n",
        "## end your code here\n",
        "\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAW4_HLmPe8D"
      },
      "source": [
        "### 173. Swap two rows of a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C80h71zHPe8D",
        "outputId": "d69dcfec-c584-4b5c-f447-b4d554a2f13f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  col_A  col_B\n",
            "0     A      1\n",
            "1     D      4\n",
            "2     C      3\n",
            "3     B      2\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
        "                   [\"C\", 3], [\"D\", 4]],\n",
        "                  columns=[\"col_A\", \"col_B\"])\n",
        "\n",
        "# swap second and last row\n",
        "row_1, row_2 = 1, 3\n",
        "\n",
        "## start your code below\n",
        "df.iloc[[row_1, row_2]] = df.iloc[[row_2, row_1]].values\n",
        "\n",
        "\n",
        "\n",
        "## end your code here\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH8J8lVVPe8D"
      },
      "source": [
        "### 174. Create a column \"col_D\" that contains the 2nd largest value in each row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwPfPPO4Pe8D",
        "outputId": "0f81e794-0ecb-45b6-9ef1-36bf3d622735"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_A</th>\n",
              "      <th>col_B</th>\n",
              "      <th>col_C</th>\n",
              "      <th>col_D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   col_A  col_B  col_C  col_D\n",
              "0      4      1      5      4\n",
              "1      5      2      9      5\n",
              "2      2      9      3      3\n",
              "3      8      5      4      5"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.DataFrame([[4, 1, 5],\n",
        "                   [5, 2, 9],\n",
        "                   [2, 9, 3],\n",
        "                   [8, 5, 4]],\n",
        "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
        "\n",
        "\n",
        "## start your code below\n",
        "df['col_D'] = df.apply(lambda x: x.nlargest(2).min(), axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# end your code here\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyCGWaEyPe8D"
      },
      "source": [
        "### 176. Get the Group \"A\" of the dataframe by first grouping the dataframe and then using the group key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5EjNC6GPe8E",
        "outputId": "49595ad3-d391-4717-a2c3-e94c4f3ff0f8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_A</th>\n",
              "      <th>col_B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  col_A  col_B\n",
              "0     A      1\n",
              "2     A      3"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.DataFrame([[\"A\", 1], [\"B\", 2],\n",
        "                   [\"A\", 3], [\"D\", 4]],\n",
        "                  columns=[\"col_A\", \"col_B\"])\n",
        "\n",
        "\n",
        "## start your code below\n",
        "group_A = df.groupby('col_A').get_group('A')\n",
        "\n",
        "\n",
        "\n",
        "## end your code here\n",
        "\n",
        "group_A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6PWZhA_Pe8E"
      },
      "source": [
        "### 178. Get the rows where the value of \"col_A\" is equal to \"col_B\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "id": "VwiSSWd5Pe8E",
        "outputId": "8147f83e-209e-41a8-fc8e-706b40838aa7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_A</th>\n",
              "      <th>col_B</th>\n",
              "      <th>col_C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   col_A  col_B  col_C\n",
              "1      5      5      9"
            ]
          },
          "execution_count": 227,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame([[4, 1, 5],\n",
        "                   [5, 5, 9],\n",
        "                   [2, 9, 3],\n",
        "                   [8, 5, 8]],\n",
        "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
        "\n",
        "\n",
        "## start your code below\n",
        "### 178. Get the rows where the value of \"col_A\" is equal to \"col_B\".\n",
        "\n",
        "df[df['col_A'] == df['col_B']]\n",
        "\n",
        "## end your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBaZqoE1Pe8E"
      },
      "source": [
        "### 180. Sort the Data on col_A and col_B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgE4yGt5Pe8F"
      },
      "source": [
        "col_A -> Ascending\n",
        "col_B -> Descending"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "rIXbUrmUPe8F",
        "outputId": "e6225844-d1a1-4e93-943e-e3e6b0cc6cc6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_A</th>\n",
              "      <th>col_B</th>\n",
              "      <th>col_C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   col_A  col_B  col_C\n",
              "1      2      5      9\n",
              "2      2      9      3\n",
              "0      4      1      5\n",
              "3      8      5      8"
            ]
          },
          "execution_count": 228,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame([[4, 1, 5],\n",
        "                   [2, 5, 9],\n",
        "                   [2, 9, 3],\n",
        "                   [8, 5, 8]],\n",
        "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
        "\n",
        "\n",
        "## start your code below\n",
        "### 180. Sort the Data on col_A and col_B\n",
        "df.sort_values(by=['col_A', 'col_B'])\n",
        "\n",
        "## end your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuV4_g_EPe8F"
      },
      "source": [
        "### 182. Get the mean of every column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "ziefgTwrPe8F",
        "outputId": "15599489-3c9f-499a-9133-3438ddd343e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "col_A    4.75\n",
            "col_B    5.00\n",
            "col_C    6.25\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame([[4, 1, 5],\n",
        "                   [5, 5, 9],\n",
        "                   [2, 9, 3],\n",
        "                   [8, 5, 8]],\n",
        "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
        "\n",
        "\n",
        "## start your code below\n",
        "mean = df.mean(axis=0)\n",
        "\n",
        "## end your code here\n",
        "\n",
        "print(mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cd9kqXQPe8G"
      },
      "source": [
        "### 182. Get the mean of every row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "QNmOWWiGPe8G",
        "outputId": "0105b52c-d308-47dd-f4a3-c2e62e7b0022"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    3.333333\n",
            "1    6.333333\n",
            "2    4.666667\n",
            "3    7.000000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame([[4, 1, 5],\n",
        "                   [5, 5, 9],\n",
        "                   [2, 9, 3],\n",
        "                   [8, 5, 8]],\n",
        "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
        "\n",
        "\n",
        "## start your code below\n",
        "mean = df.mean(axis=1)\n",
        "\n",
        "## end your code here\n",
        "\n",
        "print(mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSbmaEiDPe8G"
      },
      "source": [
        "### 183. Concatentate the two DataFrames row-wise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "2y5hJG5BPe8G",
        "outputId": "a777be01-fb23-43e9-f3e9-0c49da3d2d41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  col_A  col_B\n",
            "0     A      1\n",
            "1     B      2\n",
            "2     A      3\n",
            "3     C      4\n"
          ]
        }
      ],
      "source": [
        "df1 = pd.DataFrame([[\"A\", 1], [\"B\", 2]],\n",
        "                  columns=[\"col_A\", \"col_B\"])\n",
        "\n",
        "df2 = pd.DataFrame([[\"A\", 3], [\"C\", 4]],\n",
        "                  columns=[\"col_A\", \"col_B\"])\n",
        "\n",
        "## start your code below\n",
        "new_df = pd.concat([df1, df2], axis=0)\n",
        "new_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "## end your code here\n",
        "\n",
        "print(new_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB6zGw2IPe8H"
      },
      "source": [
        "### 184. Concatentate the two DataFrames column-wise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "id": "Y1R5RLSxPe8H",
        "outputId": "16a2d7f1-eda4-4b3f-a82c-d70abfe3f939"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  col_A  col_B col_C  col_D\n",
            "0     A    1.0   NaN    NaN\n",
            "1     B    2.0   NaN    NaN\n",
            "2   NaN    NaN     A    3.0\n",
            "3   NaN    NaN     C    4.0\n"
          ]
        }
      ],
      "source": [
        "df1 = pd.DataFrame([[\"A\", 1], [\"B\", 2]],\n",
        "                  columns=[\"col_A\", \"col_B\"])\n",
        "\n",
        "df2 = pd.DataFrame([[\"A\", 3], [\"C\", 4]],\n",
        "                  columns=[\"col_C\", \"col_D\"])\n",
        "\n",
        "## start your code below\n",
        "new_df = pd.concat([df1, df2], axis=0)\n",
        "new_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "## end your code here\n",
        "\n",
        "print(new_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDT_fAddPe8H"
      },
      "source": [
        "### 185. Change the last two values in the last column to [2,4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXi81-5PPe8H"
      },
      "source": [
        "Change 3 -> 2\n",
        "Change 8 -> 4\n",
        "\n",
        "**Note: You should do this in a single line of code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "Js16VFnuPe8H",
        "outputId": "bae18e49-16b7-4085-e6bd-f7c95ce34c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col_A  col_B  col_C\n",
            "0      4      1      5\n",
            "1      5      5      9\n",
            "2      2      9      3\n",
            "3      8      5      8\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame([[4, 1, 5],\n",
        "                   [5, 5, 9],\n",
        "                   [2, 9, 3],\n",
        "                   [8, 5, 8]],\n",
        "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
        "\n",
        "\n",
        "## start your code below\n",
        "new_df = pd.concat([df, df], axis=0)\n",
        "\n",
        "## end your code here\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Juf2-66Pe8I"
      },
      "source": [
        "### 186. Replace all '1' with '2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "nfmz1WmcPe8I",
        "outputId": "cc728c21-8072-4382-f276-80486ef01d0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col_A  col_B  col_C\n",
            "0      4      2      5\n",
            "1      5      5      2\n",
            "2      2      9      3\n",
            "3      8      5      8\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame([[4, 1, 5],\n",
        "                   [5, 5, 1],\n",
        "                   [1, 9, 3],\n",
        "                   [8, 5, 8]],\n",
        "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
        "\n",
        "\n",
        "## start your code below\n",
        "df.replace(1, 2, inplace=True)\n",
        "\n",
        "\n",
        "## end your code here\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s30cVPk7Pe8I"
      },
      "source": [
        "### 187. Replace all '1' with '2' and '5' with '6' in a single line of code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "id": "5UJN-Hr7Pe8I",
        "outputId": "d59358db-757a-40ee-a48f-b4a8ce530ebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col_A  col_B  col_C\n",
            "0      4      2      6\n",
            "1      6      6      2\n",
            "2      2      9      3\n",
            "3      8      6      8\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame([[4, 1, 5],\n",
        "                   [5, 5, 1],\n",
        "                   [1, 9, 3],\n",
        "                   [8, 5, 8]],\n",
        "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
        "\n",
        "\n",
        "## start your code below\n",
        "df.replace([1, 5], [2, 6], inplace=True)\n",
        "\n",
        "\n",
        "## end your code here\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQgW4UhrPe8J"
      },
      "source": [
        "### 189. Convert the DataFrame to a list of lists. Don't include the header row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "1ywo_MqWPe8J",
        "outputId": "e884f5a0-32fd-440e-ae2c-c6417e1c88d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[4, 1, 5], [5, 5, 1], [1, 9, 3], [8, 5, 8]]\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame([[4, 1, 5],\n",
        "                   [5, 5, 1],\n",
        "                   [1, 9, 3],\n",
        "                   [8, 5, 8]],\n",
        "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
        "\n",
        "\n",
        "## start your code below\n",
        "df.values.tolist()\n",
        "\n",
        "## end your code here\n",
        "\n",
        "print(data_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz1xs9mdPe8J"
      },
      "source": [
        "### 190. Add three new columns that show the cumulative sum of every column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "Gk9lYwGqPe8J",
        "outputId": "c9631ebe-2d63-4591-d0e8-dedbd164161a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col_A  col_B  col_C  cumsum1  cumsum2  cumsum3\n",
            "0      4      1      5        4        1        5\n",
            "1      5      5      1        9        6        6\n",
            "2      1      9      3       10       15        9\n",
            "3      8      5      8       18       20       17\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame([[4, 1, 5],\n",
        "                   [5, 5, 1],\n",
        "                   [1, 9, 3],\n",
        "                   [8, 5, 8]],\n",
        "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
        "\n",
        "\n",
        "## start your code below\n",
        "df['cumsum1'] = df['col_A'].cumsum()\n",
        "df['cumsum2'] = df['col_B'].cumsum()\n",
        "df['cumsum3'] = df['col_C'].cumsum()\n",
        "## end your code here\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qCigFOXPe8K"
      },
      "source": [
        "### 191. Print the cumulative sum of every row in a new column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VayiPXaHPe8K"
      },
      "source": [
        "### In other words, make a column that stores the cumulative sum of the (sum of every row)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "uC9GxcZNPe8K",
        "outputId": "fdc11155-6038-4319-d8a9-77b0127f480c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   col_A  col_B  col_C  cumsum\n",
            "0      4      1      5      10\n",
            "1      5      5      1      21\n",
            "2      1      9      3      34\n",
            "3      8      5      8      55\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame([[4, 1, 5],\n",
        "                   [5, 5, 1],\n",
        "                   [1, 9, 3],\n",
        "                   [8, 5, 8]],\n",
        "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
        "\n",
        "\n",
        "## start your code below\n",
        "df['cumsum'] = df.sum(axis=1).cumsum()\n",
        "\n",
        "## end your code here\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z5JOgHhPe8K"
      },
      "source": [
        "### 194. GroupBy col_A, then find the sum of col_B and mean of col_C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "-Rw6XlEaPe8K",
        "outputId": "cb116560-f209-4cdf-adf4-8e9e0ef3808a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_B</th>\n",
              "      <th>col_C</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>col_A</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>A</th>\n",
              "      <td>6</td>\n",
              "      <td>6.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C</th>\n",
              "      <td>9</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       col_B  col_C\n",
              "col_A              \n",
              "A          6    6.5\n",
              "B          5    1.0\n",
              "C          9    3.0"
            ]
          },
          "execution_count": 242,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame([[\"A\", 1, 5],\n",
        "                   [\"B\", 5, 1],\n",
        "                   [\"C\", 9, 3],\n",
        "                   [\"A\", 5, 8]],\n",
        "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
        "\n",
        "\n",
        "## start your code below\n",
        "df.groupby('col_A').agg({'col_B': 'sum', 'col_C': 'mean'})\n",
        "\n",
        "## end your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA4_0kDGPe8L"
      },
      "source": [
        "### 195. Find the correlation between every pair of column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "20Luc7I3Pe8L",
        "outputId": "208d3c5d-e0e3-4d87-974f-a1f9af788f10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "col_A\n",
            "1    9\n",
            "4    1\n",
            "5    5\n",
            "8    5\n",
            "Name: col_B, dtype: int64\n",
            "col_A\n",
            "1    3\n",
            "4    5\n",
            "5    1\n",
            "8    8\n",
            "Name: col_C, dtype: int64\n",
            "   col_A  col_B  col_C\n",
            "0      4      1      5\n",
            "1      5      5      9\n",
            "2      2      9      3\n",
            "3      8      5      8\n",
            "0      4      1      5\n",
            "1      5      5      9\n",
            "2      2      9      3\n",
            "3      8      5      8\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame([[4, 1, 5],\n",
        "                   [5, 5, 1],\n",
        "                   [1, 9, 3],\n",
        "                   [8, 5, 8]],\n",
        "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
        "\n",
        "\n",
        "sum_col_B = df.groupby(\"col_A\")[\"col_B\"].sum()\n",
        "sum_col_C = df.groupby(\"col_A\")[\"col_C\"].sum()\n",
        "\n",
        "# Display the results\n",
        "print(sum_col_B)\n",
        "print(sum_col_C)\n",
        "\n",
        "print(new_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bPI8RosPe8L"
      },
      "source": [
        "### 198. Merge the two dataframes using the join() method on col_A.\n",
        "참고) Note that the `join()` method is similar to the `merge()` method, but it operates on the index by default and has a simplified syntax.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57TodkT8Pe8M"
      },
      "source": [
        "### 199. Perform the full outer join on the two DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "VQOIzyYOPe8M",
        "outputId": "e2bb393e-d0e6-403e-b29a-35f516e38c75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  col_A  col_B  col_C\n",
            "0     A    1.0    3.0\n",
            "1     B    2.0    NaN\n",
            "2     C    NaN    4.0\n"
          ]
        }
      ],
      "source": [
        "df1 = pd.DataFrame([[\"A\", 1], [\"B\", 2]],\n",
        "                  columns=[\"col_A\", \"col_B\"])\n",
        "\n",
        "df2 = pd.DataFrame([[\"A\", 3], [\"C\", 4]],\n",
        "                  columns=[\"col_A\", \"col_C\"])\n",
        "\n",
        "## start your code below\n",
        "\n",
        "new_df = pd.merge(df1, df2, on='col_A', how='outer')\n",
        "## end your code here\n",
        "\n",
        "print(new_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riDJXX7LPe8M"
      },
      "source": [
        "### 200. Convert the DataFrame to a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "xRSfy5E3Pe8M",
        "outputId": "b53ac994-e2d9-4b91-9c45-eba13c91a410"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'col_A': {0: 4, 1: 5, 2: 1, 3: 8},\n",
              " 'col_B': {0: 1, 1: 5, 2: 9, 3: 5},\n",
              " 'col_C': {0: 5, 1: 1, 2: 3, 3: 8}}"
            ]
          },
          "execution_count": 250,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame([[4, 1, 5],\n",
        "                   [5, 5, 1],\n",
        "                   [1, 9, 3],\n",
        "                   [8, 5, 8]],\n",
        "                  columns=[\"col_A\", \"col_B\", \"col_C\"])\n",
        "\n",
        "\n",
        "## start your code below\n",
        "dict_df = df.to_dict()\n",
        "\n",
        "## end your code here\n",
        "\n",
        "dict_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_DkYvWnPe8N"
      },
      "source": [
        "### 끝.\n",
        "### 고생하셨습니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "07dac775df544b37af03c6a6f77c87ab",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
