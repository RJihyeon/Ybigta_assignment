{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "과제 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4sFYht6L1BQ",
        "outputId": "ea3e0119-747d-4276-d339-648be86c4470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected kite with confidence 0.988 at location [318.13, 93.78, 393.97, 156.52]\n",
            "Detected person with confidence 0.999 at location [597.72, 206.31, 669.59, 415.73]\n",
            "Detected kite with confidence 0.997 at location [617.86, 379.51, 731.87, 433.64]\n",
            "Detected person with confidence 0.999 at location [338.05, 232.54, 406.47, 430.02]\n",
            "Detected kite with confidence 0.958 at location [573.83, 111.01, 593.08, 165.8]\n",
            "Detected person with confidence 0.998 at location [420.16, 268.72, 479.21, 425.0]\n",
            "Detected person with confidence 0.98 at location [508.74, 250.86, 567.85, 426.96]\n"
          ]
        }
      ],
      "source": [
        "## 1번 모델 : facebook/detr-resnet-50\n",
        "\n",
        "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "import torch\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "# 로컬 이미지 파일 경로로 수정\n",
        "image_path = \"/object_detection.jpg\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# 모델과 프로세서 로드\n",
        "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
        "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
        "\n",
        "# 이미지 전처리\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "# 모델 실행\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# 결과를 COCO API 형식으로 변환\n",
        "target_sizes = torch.tensor([image.size[::-1]])\n",
        "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
        "\n",
        "# 결과 이미지 생성 및 저장\n",
        "result_image = image.copy()\n",
        "draw = ImageDraw.Draw(result_image)\n",
        "\n",
        "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "    box = [round(i, 2) for i in box.tolist()]\n",
        "    label_str = model.config.id2label[label.item()]\n",
        "    print(\n",
        "            f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
        "            f\"{round(score.item(), 3)} at location {box}\"\n",
        "    )\n",
        "\n",
        "    # 박스 그리기\n",
        "    draw.rectangle(box, outline=\"red\", width=3)\n",
        "\n",
        "    # 라벨과 신뢰도 표시\n",
        "    draw.text((box[0], box[1]), f\"Detected {label_str} with confidence {round(score.item(), 3)} at location {box}\", fill=\"red\")\n",
        "\n",
        "# 결과 이미지 저장\n",
        "result_image.save(\"/result_image.jpg\")\n",
        "\n",
        "# 결과 출력\n",
        "result_image.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUWZejxcMtQf",
        "outputId": "62624675-db1a-488b-e2a3-9e5d55845daf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected person with confidence 0.998 at location [512.8, 251.33, 573.15, 430.01]\n",
            "Detected person with confidence 0.998 at location [413.5, 269.65, 480.1, 419.68]\n",
            "Detected person with confidence 1.0 at location [336.14, 233.13, 406.06, 429.8]\n",
            "Detected kite with confidence 0.938 at location [572.64, 114.6, 589.06, 160.53]\n",
            "Detected kite with confidence 0.902 at location [614.21, 375.2, 724.22, 437.49]\n",
            "Detected person with confidence 0.999 at location [591.63, 207.01, 674.55, 415.98]\n"
          ]
        }
      ],
      "source": [
        "## 2번 모델 : YOLOS (tiny-sized) model\n",
        "from transformers import YolosImageProcessor, YolosForObjectDetection\n",
        "from PIL import Image, ImageDraw\n",
        "import torch\n",
        "\n",
        "# 로컬 이미지 파일 경로로 수정\n",
        "image_path = \"/object_detection.jpg\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# 모델과 프로세서 로드\n",
        "model = YolosForObjectDetection.from_pretrained('hustvl/yolos-tiny')\n",
        "image_processor = YolosImageProcessor.from_pretrained(\"hustvl/yolos-tiny\")\n",
        "\n",
        "# 이미지 전처리\n",
        "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "# 모델 실행\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# 결과를 COCO API 형식으로 변환\n",
        "target_sizes = torch.tensor([image.size[::-1]])\n",
        "results = image_processor.post_process_object_detection(outputs, threshold=0.9, target_sizes=target_sizes)[0]\n",
        "\n",
        "# 결과 출력\n",
        "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "    box = [round(i, 2) for i in box.tolist()]\n",
        "    print(\n",
        "        f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
        "        f\"{round(score.item(), 3)} at location {box}\"\n",
        "    )\n",
        "\n",
        "# 결과 이미지 생성 및 저장\n",
        "result_image = image.copy()\n",
        "draw = ImageDraw.Draw(result_image)\n",
        "\n",
        "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "    box = [round(i, 2) for i in box.tolist()]\n",
        "    label_str = model.config.id2label[label.item()]\n",
        "\n",
        "    # 박스 그리기\n",
        "    draw.rectangle(box, outline=\"blue\", width=3)\n",
        "\n",
        "    # 라벨과 신뢰도 표시\n",
        "    draw.text((box[0], box[1]), f\"Detected {label_str} with confidence {round(score.item(), 3)} at location {box}\", fill=\"blue\")\n",
        "\n",
        "# 결과 이미지 저장\n",
        "result_image.save(\"/result_image_yolos.jpg\")\n",
        "\n",
        "# 결과 출력\n",
        "result_image.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7Kjrz3APCmY"
      },
      "source": [
        "# **성능 비교 **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZkq3dHVvyZ5"
      },
      "source": [
        "첫 번째 모델이 두 번째 모델에 비해 성능이 뛰어나다. 두 번째 모델은 연을 2개 감지한 데에 비해 첫 번째 모델은 연 3개를 정확하게 감지하고 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "과제 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
